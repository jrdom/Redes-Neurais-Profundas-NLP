{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**O objetivo do exercício é implementar o ReAct.**\n",
        "\n",
        "* Testar no dataset do IIRC - 50-100 primeiras perguntas com resposta (excluir as None)\n",
        "* Usar o LLaMA (via groq ou ollama).\n",
        "* Instruir o modelo a seguir a sequência Thougth, Action, Input, Observation (a observação não é do próprio modelo, mas resultado da busca)\n",
        "* Instruir o modelo agir passo-a-passo (decomposição da pergunta, etc.).\n",
        "* Usar a busca como ferramenta\n",
        "* Usar o mesmo buscador do exercício de RAG\n",
        "* Pensar em outras ferramentas (ex.: calculadora para perguntas aritméticas)"
      ],
      "metadata": {
        "id": "w5yZswpPahpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala as bibliotecas necessárias com a opção '-qU', que garante uma instalação silenciosa e atualizada.\n",
        "!pip install -qU langchain sentence_transformers groq  # Instala as bibliotecas langchain, sentence_transformers e groq.\n",
        "!pip install -qU langchain-huggingface langchain-community  # Instala bibliotecas para integração com HuggingFace e a comunidade LangChain.\n",
        "!pip install -qU faiss-cpu py_expression_eval  # Instala o FAISS para indexação de vetores (versão CPU) e py_expression_eval para avaliação de expressões matemáticas.\n",
        "!pip install -qU langchain-text-splitter  # Instala a biblioteca para divisão de textos da LangChain.\n",
        "\n",
        "# Baixa o arquivo de teste do dataset IIRC (situado em um servidor na Amazon S3).\n",
        "!wget https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_test.json\n",
        "\n",
        "# Baixa um arquivo compactado (.tar.gz) que contém artigos de contexto, também hospedado no servidor S3 da Amazon.\n",
        "!wget https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz\n",
        "\n",
        "# Extrai o conteúdo do arquivo compactado baixado (context_articles.tar.gz).\n",
        "!tar -xf context_articles.tar.gz\n"
      ],
      "metadata": {
        "id": "2MC0saEHGva7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb67c78-8175-4835-fa71-c30fbe78add2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain-text-splitter (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain-text-splitter\u001b[0m\u001b[31m\n",
            "\u001b[0m--2024-10-09 21:28:40--  https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_test.json\n",
            "Resolving iirc-dataset.s3.us-west-2.amazonaws.com (iirc-dataset.s3.us-west-2.amazonaws.com)... 3.5.79.133, 52.218.217.65, 3.5.83.233, ...\n",
            "Connecting to iirc-dataset.s3.us-west-2.amazonaws.com (iirc-dataset.s3.us-west-2.amazonaws.com)|3.5.79.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2874825 (2.7M) [application/json]\n",
            "Saving to: ‘iirc_test.json.2’\n",
            "\n",
            "iirc_test.json.2    100%[===================>]   2.74M   739KB/s    in 3.8s    \n",
            "\n",
            "2024-10-09 21:28:44 (739 KB/s) - ‘iirc_test.json.2’ saved [2874825/2874825]\n",
            "\n",
            "--2024-10-09 21:28:44--  https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz\n",
            "Resolving iirc-dataset.s3.us-west-2.amazonaws.com (iirc-dataset.s3.us-west-2.amazonaws.com)... 52.92.153.210, 52.92.130.10, 3.5.77.44, ...\n",
            "Connecting to iirc-dataset.s3.us-west-2.amazonaws.com (iirc-dataset.s3.us-west-2.amazonaws.com)|52.92.153.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 385263479 (367M) [application/x-gzip]\n",
            "Saving to: ‘context_articles.tar.gz.2’\n",
            "\n",
            "context_articles.ta 100%[===================>] 367.42M  22.0MB/s    in 18s     \n",
            "\n",
            "2024-10-09 21:29:03 (20.6 MB/s) - ‘context_articles.tar.gz.2’ saved [385263479/385263479]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importação de bibliotecas necessárias\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter  # Divisor de texto recursivo da LangChain\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings  # Gera embeddings usando HuggingFace\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score  # Métricas de avaliação (precisão, recall, F1-score)\n",
        "from py_expression_eval import Parser  # Avaliador de expressões matemáticas\n",
        "from collections import Counter  # Contador para operações com coleções\n",
        "from groq import Groq  # Cliente da API Groq\n",
        "from tqdm import tqdm  # Barra de progresso\n",
        "import numpy as np  # Biblioteca para operações numéricas\n",
        "import json  # Manipulação de arquivos JSON\n",
        "import faiss  # Ferramenta para indexação e busca de vetores\n",
        "import re  # Biblioteca de expressões regulares\n",
        "\n",
        "# Configuração da chave da API para Groq\n",
        "API_KEY = \"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\"\n",
        "\n",
        "# Inicialização do cliente Groq com a chave da API fornecida\n",
        "groq_client = Groq(api_key=API_KEY)\n",
        "\n",
        "# Exibe os métodos e atributos disponíveis no cliente Groq\n",
        "print(dir(groq_client))  # Isso irá imprimir todos os métodos e atributos disponíveis\n"
      ],
      "metadata": {
        "id": "nOrzPiPFHanj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfbf018-28e9-4052-9dea-8592d567b4e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_base_url', '_build_headers', '_build_request', '_calculate_retry_timeout', '_client', '_custom_headers', '_custom_query', '_default_stream_cls', '_enforce_trailing_slash', '_idempotency_header', '_idempotency_key', '_is_protocol', '_limits', '_make_sse_decoder', '_make_status_error', '_make_status_error_from_response', '_maybe_override_cast_to', '_parse_retry_after_header', '_platform', '_prepare_options', '_prepare_request', '_prepare_url', '_process_response', '_process_response_data', '_proxies', '_remaining_retries', '_request', '_request_api_list', '_retry_request', '_serialize_multipartform', '_should_retry', '_should_stream_response_body', '_strict_response_validation', '_transport', '_validate_headers', '_version', 'api_key', 'audio', 'auth_headers', 'base_url', 'chat', 'close', 'copy', 'custom_auth', 'default_headers', 'default_query', 'delete', 'embeddings', 'get', 'get_api_list', 'is_closed', 'max_retries', 'models', 'patch', 'platform_headers', 'post', 'put', 'qs', 'request', 'timeout', 'user_agent', 'with_options', 'with_raw_response', 'with_streaming_response']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Carregamento dos dados a partir de arquivos JSON\n",
        "\n",
        "# Carrega os artigos de contexto do arquivo 'context_articles.json' para a variável 'context_articles'\n",
        "with open(\"context_articles.json\", 'r') as file:\n",
        "    context_articles = json.load(file)  # Armazena os dados carregados em 'context_articles'\n",
        "\n",
        "# Carrega os dados de teste do arquivo 'iirc_test.json' para a variável 'data'\n",
        "with open(\"iirc_test.json\", 'r') as file:\n",
        "    data = json.load(file)  # Armazena os dados carregados em 'data'\n"
      ],
      "metadata": {
        "id": "Q_l5XJTLHmHd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Função para filtrar respostas do tipo 'none'\n",
        "def exclude_none_answers(data):\n",
        "    filtered_data = []  # Lista para armazenar os itens filtrados\n",
        "    for item in data:\n",
        "        filtered_questions = []  # Lista temporária para armazenar as perguntas filtradas\n",
        "        for question in item['questions']:\n",
        "            # Verifica se a resposta não é do tipo 'none'\n",
        "            if question['answer']['type'] != 'none':\n",
        "                question['title'] = item['title']  # Adiciona o título do item à pergunta\n",
        "                filtered_questions.append(question)  # Adiciona a pergunta filtrada à lista\n",
        "        if filtered_questions:  # Se houver perguntas filtradas\n",
        "            filtered_item = item.copy()  # Faz uma cópia do item original\n",
        "            filtered_item['questions'] = filtered_questions  # Substitui as perguntas pelo conjunto filtrado\n",
        "            filtered_data.append(filtered_item)  # Adiciona o item filtrado à lista final\n",
        "    return filtered_data  # Retorna a lista final com as perguntas filtradas\n",
        "\n",
        "# Imprime o total de perguntas antes do filtro\n",
        "print(f'Total questions: {len(data)}')\n",
        "\n",
        "# Aplica o filtro para remover respostas do tipo 'none'\n",
        "filter_data = exclude_none_answers(data)\n",
        "\n",
        "# Imprime o total de perguntas após o filtro\n",
        "print(f'Filter questions: {len(filter_data)}')\n",
        "\n",
        "# Exibe uma amostra dos dados filtrados\n",
        "print(\"\\n===> Show one sample <===\")\n",
        "filter_data[0]\n"
      ],
      "metadata": {
        "id": "fykcytMqIAG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6714b12-1f98-4330-9140-27415f48e33c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total questions: 514\n",
            "Filter questions: 435\n",
            "\n",
            "===> Show one sample <===\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'questions': [{'answer': {'type': 'span',\n",
              "    'answer_spans': [{'text': 'sky and thunder god',\n",
              "      'passage': 'zeus',\n",
              "      'type': 'answer',\n",
              "      'start': 83,\n",
              "      'end': 102}]},\n",
              "   'question': 'What is Zeus know for in Greek mythology?',\n",
              "   'context': [{'text': 'he Palici the sons of Zeus',\n",
              "     'passage': 'main',\n",
              "     'indices': [684, 710]},\n",
              "    {'text': 'in Greek mythology', 'passage': 'main', 'indices': [137, 155]},\n",
              "    {'text': 'Zeus (British English , North American English ; , Zeús ) is the sky and thunder god in ancient Greek religion',\n",
              "     'passage': 'Zeus',\n",
              "     'indices': [0, 110]}],\n",
              "   'question_links': ['Greek mythology', 'Zeus'],\n",
              "   'title': 'Palici'}],\n",
              " 'text': \"The Palici (Παλικοί in Greek), or Palaci, were a pair of indigenous Sicilian chthonic deities in Roman mythology, and to a lesser extent in Greek mythology. They are mentioned in Ovid's Metamorphoses V, 406, and in Virgil's Aeneid IX, 585. Their cult centered on three small lakes that emitted sulphurous vapors in the Palagonia plain, and as a result these twin brothers were associated with geysers and the underworld. There was also a shrine to the Palaci in Palacia, where people could subject themselves or others to tests of reliability through divine judgement; passing meant that an oath could be trusted. The mythological lineage of the Palici is uncertain; one legend made the Palici the sons of Zeus, or possibly Hephaestus, by Aetna or Thalia, but another claimed that the Palici were the sons of the Sicilian deity Adranus.\\n\",\n",
              " 'links': [{'target': 'Sicily', 'indices': [68, 76]},\n",
              "  {'target': 'Chthonic', 'indices': [77, 85]},\n",
              "  {'target': 'Roman mythology', 'indices': [97, 112]},\n",
              "  {'target': 'Greek mythology', 'indices': [140, 155]},\n",
              "  {'target': 'Ovid', 'indices': [179, 183]},\n",
              "  {'target': 'Virgil', 'indices': [215, 221]},\n",
              "  {'target': 'Palagonia', 'indices': [319, 328]},\n",
              "  {'target': 'Geyser', 'indices': [393, 400]},\n",
              "  {'target': 'Zeus', 'indices': [706, 710]},\n",
              "  {'target': 'Hephaestus', 'indices': [724, 734]},\n",
              "  {'target': 'Aetna (nymph)', 'indices': [739, 744]},\n",
              "  {'target': 'Thalia (nymph)', 'indices': [748, 754]},\n",
              "  {'target': 'Adranus', 'indices': [828, 835]}],\n",
              " 'title': 'Palici'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Carregamento dos documentos\n",
        "# Adaptado de Visconde https://github.com/neuralmind-ai/visconde\n",
        "\n",
        "num_questions = 50  # Define o número de perguntas a serem consideradas\n",
        "\n",
        "documents = []  # Lista para armazenar os documentos carregados\n",
        "all_titles = []  # Lista para rastrear títulos já adicionados\n",
        "\n",
        "# Itera sobre os itens filtrados (limitado pelo número de perguntas definido)\n",
        "for item in filter_data[:num_questions]:\n",
        "    # Verifica se o título do item (em minúsculas) ainda não foi adicionado\n",
        "    if item['title'].lower() not in all_titles:\n",
        "        # Adiciona o documento principal à lista de documentos\n",
        "        documents.append({\n",
        "            \"title\": item['title'],  # Título do documento\n",
        "            \"content\": item[\"text\"]   # Conteúdo do documento\n",
        "        })\n",
        "        all_titles.append(item['title'].lower())  # Armazena o título na lista de títulos já processados\n",
        "\n",
        "    # Itera sobre os links do item para carregar documentos relacionados\n",
        "    for link in item[\"links\"]:\n",
        "        # Verifica se o link do alvo está nos artigos de contexto e não foi adicionado ainda\n",
        "        if link['target'].lower() in context_articles and link['target'].lower() not in all_titles:\n",
        "            # Adiciona o documento relacionado ao artigo de contexto\n",
        "            documents.append({\n",
        "                \"title\": link['target'],  # Título do documento\n",
        "                \"content\": context_articles[link['target'].lower()]  # Conteúdo do documento a partir dos artigos de contexto\n",
        "            })\n",
        "            all_titles.append(link['target'].lower())  # Armazena o título do link processado\n",
        "        else:\n",
        "            # Se o documento já foi carregado, exibe uma mensagem indicando isso\n",
        "            print(f\"Loaded doc: {link['target'].lower()}\")\n",
        "\n",
        "# Imprime o total de documentos carregados\n",
        "print(f'Total documents: {len(documents)}')\n"
      ],
      "metadata": {
        "id": "ouYLKx4-Ibrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65554e91-4a43-44a6-8d77-671d218a3ef3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded doc: 9th paratroopers assault regiment \"col moschin\"\n",
            "Loaded doc: goldfinger (film)\n",
            "Loaded doc: list of international cricket council members\n",
            "Loaded doc: icc americas championship\n",
            "Loaded doc: the rev\n",
            "Loaded doc: avenged sevenfold\n",
            "Loaded doc: fox footy\n",
            "Loaded doc: herald sun\n",
            "Loaded doc: fox footy\n",
            "Loaded doc: herald sun\n",
            "Loaded doc: united states\n",
            "Loaded doc: judeo-iraqi arabic\n",
            "Loaded doc: maya civilization\n",
            "Loaded doc: black watch\n",
            "Loaded doc: suicidal tendencies\n",
            "Loaded doc: western hockey league\n",
            "Loaded doc: national hockey league\n",
            "Loaded doc: home run\n",
            "Loaded doc: minor league baseball\n",
            "Loaded doc: colonel\n",
            "Loaded doc: colonel\n",
            "Loaded doc: israel\n",
            "Loaded doc: harvard business review\n",
            "Loaded doc: american football\n",
            "Loaded doc: college football\n",
            "Loaded doc: united states\n",
            "Loaded doc: billboard 200\n",
            "Loaded doc: romeo discography\n",
            "Loaded doc: billboard 200\n",
            "Loaded doc: master p\n",
            "Loaded doc: hip hop history\n",
            "Loaded doc: billboard 200\n",
            "Loaded doc: louisiana\n",
            "Loaded doc: arizona\n",
            "Loaded doc: state farm stadium\n",
            "Loaded doc: louisiana\n",
            "Loaded doc: united states\n",
            "Loaded doc: gulf of mexico\n",
            "Loaded doc: saffir–simpson scale\n",
            "Loaded doc: forgotten realms\n",
            "Loaded doc: list of dungeons & dragons rulebooks\n",
            "Loaded doc: mexico\n",
            "Loaded doc: napoleon iii\n",
            "Loaded doc: american football\n",
            "Loaded doc: national football league\n",
            "Total documents: 728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Divisão de texto em chunks (partes menores)\n",
        "\n",
        "# Inicializa o divisor de texto com os parâmetros definidos\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Lista padrão de separadores usados para dividir o texto\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # Prioridade dos separadores: parágrafo, nova linha, espaço, e vazio\n",
        "    chunk_size=1000,  # Tamanho máximo de cada chunk (parte)\n",
        "    chunk_overlap=100,  # Quantidade de sobreposição entre os chunks\n",
        "    length_function=len,  # Função utilizada para calcular o tamanho do chunk\n",
        "    is_separator_regex=False,  # Define se os separadores são expressões regulares (nesse caso, não são)\n",
        ")\n",
        "\n",
        "# Cria uma lista com os conteúdos de cada documento\n",
        "contents = [doc['content'] for doc in documents]\n",
        "\n",
        "# Divisão (chunking) dos conteúdos em partes menores\n",
        "chunks = []  # Lista para armazenar os chunks resultantes\n",
        "for content in contents:\n",
        "    # Divide o conteúdo e adiciona os chunks resultantes à lista\n",
        "    chunks.extend(text_splitter.split_text(content))\n",
        "\n",
        "# Exibe o total de chunks gerados\n",
        "print(f'Total chunks: {len(chunks)}')\n",
        "\n",
        "# Exibe o comprimento dos primeiros 10 chunks\n",
        "print(\"\\nLength of the first 10 chunks:\")\n",
        "print([len(text) for text in chunks][:10])\n",
        "\n",
        "# Exibe uma amostra do primeiro chunk gerado\n",
        "print(\"\\n===> Show one sample <===\")\n",
        "print(chunks[0])\n"
      ],
      "metadata": {
        "id": "_nDN3bX7Iziz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d38a43-2bd7-4d97-9da8-8fb40a1795ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 33037\n",
            "\n",
            "Length of the first 10 chunks:\n",
            "[836, 992, 976, 948, 385, 596, 750, 739, 943, 775]\n",
            "\n",
            "===> Show one sample <===\n",
            "The Palici (Παλικοί in Greek), or Palaci, were a pair of indigenous Sicilian chthonic deities in Roman mythology, and to a lesser extent in Greek mythology. They are mentioned in Ovid's Metamorphoses V, 406, and in Virgil's Aeneid IX, 585. Their cult centered on three small lakes that emitted sulphurous vapors in the Palagonia plain, and as a result these twin brothers were associated with geysers and the underworld. There was also a shrine to the Palaci in Palacia, where people could subject themselves or others to tests of reliability through divine judgement; passing meant that an oath could be trusted. The mythological lineage of the Palici is uncertain; one legend made the Palici the sons of Zeus, or possibly Hephaestus, by Aetna or Thalia, but another claimed that the Palici were the sons of the Sicilian deity Adranus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download do modelo para calcular embeddings\n",
        "\n",
        "# Inicializa o modelo de embeddings utilizando HuggingFace (modelo pré-treinado específico)\n",
        "model_emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# Exemplo de texto para gerar embeddings\n",
        "text = \"This is a test document.\"  # Texto de entrada para teste\n",
        "query_result = model_emb.embed_query(text)  # Gera o embedding para o texto fornecido\n",
        "\n",
        "# Exibe o exemplo de geração de embeddings\n",
        "print(\"\\n\\nExample to generate embeddings\")\n",
        "print(f'Text input: {text}')  # Exibe o texto de entrada\n",
        "print(f'Embedding size: {len(query_result)}')  # Exibe o tamanho do embedding gerado\n",
        "print(f'Embedding sample: {query_result[:3]}')  # Exibe uma amostra dos primeiros 3 valores do embedding\n"
      ],
      "metadata": {
        "id": "8gE446vuJErt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4227fd6-4dd7-4833-dfcb-d51c0456d89b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Example to generate embeddings\n",
            "Text input: This is a test document.\n",
            "Embedding size: 768\n",
            "Embedding sample: [-0.04895172640681267, -0.039861924946308136, -0.021562771871685982]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cálculo dos embeddings para cada chunk (parte menor de texto)\n",
        "\n",
        "# Criação de batches (lotes) usando list comprehension\n",
        "batch_size = 128  # Define o tamanho de cada lote\n",
        "# Divide os chunks em lotes de tamanho definido (batch_size)\n",
        "batches = [chunks[i:i + batch_size] for i in range(0, len(chunks), batch_size)]\n",
        "\n",
        "# Lista para armazenar os embeddings calculados\n",
        "embeddings_list = []\n",
        "\n",
        "# Itera sobre cada lote de chunks e calcula os embeddings\n",
        "for chunk in tqdm(batches):  # Usa tqdm para visualizar o progresso da operação\n",
        "    embedding = model_emb.embed_documents(chunk)  # Calcula os embeddings para os documentos no lote\n",
        "    embeddings_list.extend(embedding)  # Adiciona os embeddings calculados à lista final\n",
        "\n",
        "# Exibe o total de embeddings gerados\n",
        "print(f'Total embeddings: {len(embeddings_list)}')\n",
        "\n",
        "# Exibe a dimensão (tamanho) dos embeddings gerados\n",
        "print(f\"Embedding dimension: {len(embeddings_list[0])}\")\n"
      ],
      "metadata": {
        "id": "SXQiQ1mbJb8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8a5f3d-5baa-44db-9032-ab89417a894a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 259/259 [10:38<00:00,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total embeddings: 33037\n",
            "Embedding dimension: 768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Criação do índice FAISS\n",
        "\n",
        "# Converte a lista de embeddings para um array numpy\n",
        "embeddings_array = np.array(embeddings_list)\n",
        "\n",
        "# Define a dimensão dos embeddings com base no tamanho do primeiro vetor\n",
        "dimension = len(embeddings_array[0])\n",
        "\n",
        "# Cria o índice FAISS usando a métrica de distância L2 (distância euclidiana)\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Adiciona os embeddings ao índice FAISS\n",
        "index.add(embeddings_array)\n",
        "\n",
        "# Salva o índice em um arquivo\n",
        "faiss.write_index(index, 'index_file.index')\n"
      ],
      "metadata": {
        "id": "Ox5F9PhgJ9k8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Carregamento do índice FAISS\n",
        "\n",
        "# Lê o arquivo de índice FAISS previamente salvo\n",
        "index = faiss.read_index('index_file.index')\n"
      ],
      "metadata": {
        "id": "CIOjUX7wKO9Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ferramentas\n",
        "\n",
        "# Função para recuperar chunks (partes menores de texto) relevantes com base em uma query\n",
        "def retrieve_chunks(query, k, model, chunks):\n",
        "    # Gera o embedding da query\n",
        "    query_embedding = model.embed_query(query)\n",
        "\n",
        "    # Converte o embedding da query para um array numpy com o formato correto\n",
        "    query_embedding = np.array([query_embedding])\n",
        "\n",
        "    # Realiza a busca pelos k vizinhos mais próximos no índice FAISS\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    # Recupera os chunks correspondentes aos índices encontrados\n",
        "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
        "\n",
        "    return retrieved_chunks\n",
        "\n",
        "# Calculadora para avaliar expressões matemáticas simples\n",
        "parser = Parser()  # Inicializa o parser para a calculadora\n",
        "def calculator(str):\n",
        "    return parser.parse(str).evaluate({})  # Avalia a expressão passada como string\n",
        "\n",
        "# Exemplo de consulta usando o embedding da query\n",
        "query = \"Your search query here\"  # Exemplo de consulta de pesquisa\n",
        "similar_docs = retrieve_chunks(query, k=1, model=model_emb, chunks=chunks)  # Recupera o chunk mais relevante\n",
        "\n",
        "# Exibe o resultado da ferramenta de recuperação de chunks\n",
        "print(\"Ferramenta de Teste: Chunks Recuperados:\")\n",
        "print(f\"Consulta: {query}\")\n",
        "for i, doc in enumerate(similar_docs):\n",
        "    print(f\"[Documento {i+1}] : {doc}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Exemplo de uso da calculadora para avaliar uma expressão matemática\n",
        "str_sum = \"2 + 2 / 2\"\n",
        "print(\"\\n\\nFerramenta de Teste: Calculadora:\")\n",
        "print(f\"Expressão matemática: {str_sum}\")\n",
        "print(f\"Resultado: {calculator(str_sum)}\")\n"
      ],
      "metadata": {
        "id": "D-oFWOYbLCMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc59528-296d-4f78-d5d8-49e82f683899"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ferramenta de Teste: Chunks Recuperados:\n",
            "Consulta: Your search query here\n",
            "[Documento 1] : <a href=\"Zendesk\">Zendesk</a>, <a href=\"Full%20Compass%20Systems\">Full Compass Systems</a>, <a href=\"Raven%20Software\">Raven Software</a>, and <a href=\"TDS%20Telecom\">TDS Telecom</a>.\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Ferramenta de Teste: Calculadora:\n",
            "Expressão matemática: 2 + 2 / 2\n",
            "Resultado: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Definição do agente\n",
        "\n",
        "\n",
        "System_prompt = \"\"\"\n",
        "\n",
        "Your task is to answer questions given the context information and not rely on prior knowledge. If you cannot answer the question, request assistance or use a tool.\n",
        "\n",
        "You have access to the following tools:\n",
        "\n",
        "Retrieval: useful when you need to answer questions about current events or information not provided in the context. The action input should be the relevant information about the question, possibly split into subquestions.\n",
        "\n",
        "Calculator: useful when you need to calculate mathematical expressions. The action input is a string representing the mathematical expression, e.g., \"2 + 2\".\n",
        "\n",
        "Response To Question: use this action when you are ready to provide the final answer to the question.\n",
        "\n",
        "You will receive a question, then you should start a loop and do the following steps:\n",
        "\n",
        "Thought: you should always think about what to do.\n",
        "Action: the action to take, should be one of [Retrieval, Calculator, Response To Question].\n",
        "Action Input: \"the input to the action, to be sent to the tool.\"\n",
        "\n",
        "After this, wait for the human to respond with an Observation, then you can continue.\n",
        "\n",
        "If you have found the information needed to answer the question, you should use the following format:\n",
        "Thought: you should always think about what to do.\n",
        "Action: Response To Question\n",
        "Response: \"Return the concise, exact, and short answer to the question without any reasoning. If the answer is not clear, return 'None'. If applicable, provide the numerical value with its unit.\"\n",
        "\n",
        "Begin!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Função para extrair a ação do texto\n",
        "def extract_action(text):\n",
        "    action_pattern = r'Action: (.*)'  # Padrão para capturar a ação\n",
        "    action = re.search(action_pattern, text)\n",
        "    if action:\n",
        "        return action.group(1).strip().lower()  # Retorna a ação encontrada em minúsculas\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Função para extrair o input da ação\n",
        "def extract_input(text):\n",
        "    input_pattern = r'Action Input: \"(.*?)\"'  # Padrão para capturar o input da ação\n",
        "    input = re.search(input_pattern, text)\n",
        "    if input:\n",
        "        return input.group(1).strip()  # Retorna o input encontrado\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Função para extrair a resposta do texto\n",
        "def extract_response(text):\n",
        "    observation_pattern = r'Response: (.*)'  # Padrão para capturar a resposta\n",
        "    observation = re.search(observation_pattern, text)\n",
        "    if observation:\n",
        "        return observation.group(1).strip()  # Retorna a resposta encontrada\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Função para verificar se o texto é uma expressão matemática\n",
        "def is_math_expr(text):\n",
        "    \"\"\"\n",
        "    Usa uma expressão regular para verificar se o texto é uma\n",
        "    expressão matemática entre dois números (ex: \"10 + 5\", \"2 * 4\").\n",
        "    \"\"\"\n",
        "    pattern = r\"^\\d+(\\s*[\\+\\-\\*\\/]\\s*\\d+)+$\"\n",
        "    match = re.match(pattern, text)\n",
        "    return bool(match)\n",
        "\n",
        "# Função principal do agente, que processa a consulta e utiliza ferramentas conforme necessário\n",
        "def Stream_agent(query, max_steps=5, debug=False):\n",
        "    messages = [\n",
        "        { \"role\": \"system\", \"content\": System_prompt },  # Mensagem inicial do sistema\n",
        "        { \"role\": \"user\", \"content\": query },  # Consulta do usuário\n",
        "    ]\n",
        "\n",
        "    # Etapa 1: recebe a mensagem do usuário\n",
        "    if debug:\n",
        "        print(\"\\n\\n\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"[DEBUG] Question: {query}\")\n",
        "\n",
        "    # Etapa 2: gera chamadas para as ferramentas (se necessário)\n",
        "    steps = 0\n",
        "    while True:\n",
        "        response = client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=\"llama3-70b-8192\",  # Modelo utilizado\n",
        "            temperature=0.1  # Controla a aleatoriedade da resposta\n",
        "        )\n",
        "        response_message = response.choices[0].message.content\n",
        "        if debug:\n",
        "            print(f\"\\n>> {response_message}\")\n",
        "\n",
        "        # Extrai a ação e o input da ação da resposta\n",
        "        action = extract_action(response_message)\n",
        "        action_input = extract_input(response_message)\n",
        "        if debug:\n",
        "            print(f\"[DEBUG] Action: {action}\")\n",
        "            print(f\"[DEBUG] Action Input: {action_input}\")\n",
        "\n",
        "        # Inicializa a observação\n",
        "        observation = None\n",
        "        if action == \"retrieval\":\n",
        "            if action_input is None:\n",
        "                # Se o input estiver vazio, usa a query como input\n",
        "                action_input = query\n",
        "            observation = \"\"\n",
        "            tool_ans = retrieve_chunks(action_input, k=3, model=model_emb, chunks=chunks)  # Usa a ferramenta de busca\n",
        "            for i, doc in enumerate(tool_ans):\n",
        "                observation += f\"[Document {i+1}] : {doc}\\n\"\n",
        "\n",
        "        elif action == \"calculator\":\n",
        "            observation = \"The Action Input is not a valid math expression. Valid expression is: 2 + 2\"\n",
        "            if is_math_expr(action_input):  # Verifica se a expressão é matemática\n",
        "                observation = calculator(action_input)\n",
        "\n",
        "        elif action == \"response to question\":\n",
        "            response = extract_response(response_message)  # Extrai a resposta final\n",
        "            if debug:\n",
        "                print(f\"[DEBUG] Response: {response}\")\n",
        "            return response\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            observation = \"Invalid action, should be one of [Retrieval, Calculator]\"\n",
        "\n",
        "        if debug:\n",
        "            print(f\"[DEBUG] Observation: {observation}\")\n",
        "\n",
        "        # Adiciona as mensagens ao histórico de conversas\n",
        "        messages.extend([\n",
        "            { \"role\": \"system\", \"content\": response_message },\n",
        "            { \"role\": \"user\", \"content\": f\"Observation: {observation}\" },\n",
        "        ])\n",
        "\n",
        "        steps += 1\n",
        "        if steps >= max_steps:\n",
        "            if debug:\n",
        "                print(\"Maximum number of steps reached. Stopping.\")\n",
        "            return None\n",
        "            break\n",
        "\n",
        "# Função para responder a múltiplas perguntas\n",
        "def answer_questions(user_question, debug=False):\n",
        "    results = {}\n",
        "    results[\"Question\"] = []\n",
        "    results[\"Model response\"] = []\n",
        "    results[\"Ground truth\"] = []\n",
        "\n",
        "    n_questions = len(user_question)\n",
        "    i = 1\n",
        "    for item in user_question:\n",
        "        print(f\"Question: [{i}/{n_questions}]\")\n",
        "        i += 1\n",
        "        query = item['questions'][0]['question']  # Extrai a pergunta\n",
        "\n",
        "        # Executa o agente para obter a resposta\n",
        "        response = Stream_agent(query, debug=debug)\n",
        "\n",
        "        # Adaptação do Visconde https://github.com/neuralmind-ai/visconde\n",
        "        hit = item['questions'][0]\n",
        "        true_answer = \"\"\n",
        "        if hit['answer']['type'] == 'span':\n",
        "            true_answer = \", \".join([a['text'] for a in hit['answer'][\"answer_spans\"]])\n",
        "        elif hit['answer']['type'] == 'value':\n",
        "            true_answer = \"{0} {1}\".format(hit['answer']['answer_value'], hit['answer']['answer_unit'])\n",
        "        elif hit['answer']['type'] == \"binary\":\n",
        "            true_answer = hit['answer']['answer_value']\n",
        "        else:\n",
        "            print(\"Answer type not supported\")\n",
        "            true_answer = \"\"\n",
        "\n",
        "        results[\"Question\"].append(query)\n",
        "        results[\"Model response\"].append(response)\n",
        "        results[\"Ground truth\"].append(true_answer)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Inicializa o cliente da API Groq\n",
        "client = Groq(\n",
        "    api_key=API_KEY,\n",
        ")\n"
      ],
      "metadata": {
        "id": "QWQy32byM_E9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Depuração do processo de resposta do agente e processo de resposta para um conjunto de perguntas\n",
        "\n",
        "import random\n",
        "\n",
        "# Seleciona 4 perguntas aleatórias de 'filter_data'\n",
        "random_questions = random.sample(filter_data, 4)\n",
        "\n",
        "# Adiciona a quarta pergunta (o quarto item de 'filter_data')\n",
        "random_questions.append(filter_data[4])\n",
        "\n",
        "# Função para dividir as perguntas em lotes menores e processá-las\n",
        "def process_questions_in_batches(questions, batch_size=2):\n",
        "    results = {\"Question\": [], \"Ground truth\": [], \"Model response\": []}\n",
        "    for i in range(0, len(questions), batch_size):\n",
        "        batch = questions[i:i + batch_size]\n",
        "        batch_results = answer_questions(batch, debug=True)\n",
        "        # Combina os resultados e filtra quaisquer entradas que contenham None\n",
        "        combined_results = zip(\n",
        "            batch_results[\"Question\"],\n",
        "            batch_results[\"Ground truth\"],\n",
        "            batch_results[\"Model response\"]\n",
        "        )\n",
        "        filtered_results = [\n",
        "            (q, gt, mr) for q, gt, mr in combined_results if None not in (q, gt, mr)\n",
        "        ]\n",
        "        for q, gt, mr in filtered_results:\n",
        "            results[\"Question\"].append(q)\n",
        "            results[\"Ground truth\"].append(gt)\n",
        "            results[\"Model response\"].append(mr)\n",
        "    return results\n",
        "\n",
        "# Processa as perguntas em lotes de tamanho 2 para evitar exceder o limite de contexto\n",
        "results = process_questions_in_batches(random_questions, batch_size=2)\n",
        "\n",
        "# Exibe o número de perguntas processadas\n",
        "n = len(results[\"Question\"])\n",
        "print(\"\\n\\n===> Final response <===\")\n",
        "\n",
        "# Itera sobre todas as perguntas processadas e exibe as perguntas, respostas reais e as respostas do modelo\n",
        "for i in range(n):\n",
        "    print(f\"Pergunta: {results['Question'][i]}\")\n",
        "    print(f\"Resposta verdadeira: {results['Ground truth'][i]}\")\n",
        "    print(f\"Resposta gerada pelo modelo: {results['Model response'][i]}\")\n",
        "    print(\"\\n\")  # Adiciona um espaço entre cada resposta para melhor visualização\n",
        "\n",
        "num_questions = 50  # Define o número de perguntas a serem processadas\n",
        "# Chama a função 'answer_questions' para processar as perguntas filtradas até o limite definido\n",
        "results = answer_questions(filter_data[:num_questions])\n",
        "\n",
        "# Remove entradas com None dos resultados\n",
        "combined_results = zip(\n",
        "    results[\"Question\"],\n",
        "    results[\"Ground truth\"],\n",
        "    results[\"Model response\"]\n",
        ")\n",
        "filtered_results = [\n",
        "    (q, gt, mr) for q, gt, mr in combined_results if None not in (q, gt, mr)\n",
        "]\n",
        "# Separa os resultados filtrados de volta nos respectivos campos\n",
        "if filtered_results:\n",
        "    results[\"Question\"], results[\"Ground truth\"], results[\"Model response\"] = zip(*filtered_results)\n",
        "else:\n",
        "    results[\"Question\"], results[\"Ground truth\"], results[\"Model response\"] = [], [], []\n",
        "\n",
        "# Exibe o total de perguntas processadas\n",
        "print(f'Total de perguntas: {len(results[\"Question\"])}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LLeiASEQqee",
        "outputId": "4006c9be-8746-4df8-a8dc-8a42fee44ae7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: [1/2]\n",
            "\n",
            "\n",
            "\n",
            "==================================================\n",
            "[DEBUG] Question: Do Wowowin and Bubble Gang has any of the same cast members?\n",
            "\n",
            ">> Thought: I need to find information about the cast members of Wowowin and Bubble Gang to determine if they have any common cast members.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Cast members of Wowowin and Bubble Gang, Philippine TV shows\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Cast members of Wowowin and Bubble Gang, Philippine TV shows\n",
            "[DEBUG] Observation: [Document 1] : Founder.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a>\n",
            "</li><li>- <a href=\"Reckless%20Youth\">Reckless Youth</a>\n",
            "</li></ul>\n",
            "Owner.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2002–present)\n",
            "</li><li>- The Titor Conglomerate (storyline) (2010–2013)\n",
            "</li><li>- <a href=\"Robbie%20Ellis\">Robbie Ellis</a> (storyline) (2014–present)\n",
            "</li></ul>\n",
            "Commissioner.<ul><li>- <a href=\"Bob%20Saget\">Bob Saget</a> (2006–2008)\n",
            "</li><li>- <a href=\"Dave%20Coulier\">Dave Coulier</a> (2008–2010)\n",
            "</li></ul>\n",
            "Director of Fun.<ul><li>- Leonard F. Chikarason (2005–2009)\n",
            "</li><li>- <a href=\"Dieter%20VonSteigerwalt\">Dieter VonSteigerwalt</a> (2009–2010)\n",
            "</li><li>- Wink Vavasseur (2010–2013)\n",
            "</li><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2014–2017)\n",
            "</li><li>- Bryce Remsburg – acting/interim director of Fun (2016)\n",
            "</li><li>- Bryce Remsburg (2017–present)\n",
            "</li></ul>\n",
            "[Document 2] : Ali Khan Pataudi</a>, <a href=\"Mansoor%20Ali%20Khan%20Pataudi\">Mansoor Ali Khan Pataudi</a>, <a href=\"M.%20J.%20K.%20Smith\">M. J. K. Smith</a>, and <a href=\"Pelham%20Warner\">Pelham Warner</a>.\n",
            "[Document 3] : </li><li>- Mona Chong as a Chinese girl\n",
            "</li><li>- Sylvana Henriques as a Jamaican girl\n",
            "</li><li>- Dani Sheridan as an American girl\n",
            "</li><li>- <a href=\"Zaheera\">Zaheera</a> as Zara, an Indian girl\n",
            "</li><li>- Ingrit Back as a German girl\n",
            "</li><li>- Helena Ronee as an Israeli girl\n",
            "</li></ul>\n",
            "\n",
            "\n",
            ">> Thought: The provided documents do not seem to contain information about the cast members of Wowowin and Bubble Gang, which are Philippine TV shows.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Cast members of Wowowin and Bubble Gang, Philippine TV shows\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Cast members of Wowowin and Bubble Gang, Philippine TV shows\n",
            "[DEBUG] Observation: [Document 1] : Founder.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a>\n",
            "</li><li>- <a href=\"Reckless%20Youth\">Reckless Youth</a>\n",
            "</li></ul>\n",
            "Owner.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2002–present)\n",
            "</li><li>- The Titor Conglomerate (storyline) (2010–2013)\n",
            "</li><li>- <a href=\"Robbie%20Ellis\">Robbie Ellis</a> (storyline) (2014–present)\n",
            "</li></ul>\n",
            "Commissioner.<ul><li>- <a href=\"Bob%20Saget\">Bob Saget</a> (2006–2008)\n",
            "</li><li>- <a href=\"Dave%20Coulier\">Dave Coulier</a> (2008–2010)\n",
            "</li></ul>\n",
            "Director of Fun.<ul><li>- Leonard F. Chikarason (2005–2009)\n",
            "</li><li>- <a href=\"Dieter%20VonSteigerwalt\">Dieter VonSteigerwalt</a> (2009–2010)\n",
            "</li><li>- Wink Vavasseur (2010–2013)\n",
            "</li><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2014–2017)\n",
            "</li><li>- Bryce Remsburg – acting/interim director of Fun (2016)\n",
            "</li><li>- Bryce Remsburg (2017–present)\n",
            "</li></ul>\n",
            "[Document 2] : Ali Khan Pataudi</a>, <a href=\"Mansoor%20Ali%20Khan%20Pataudi\">Mansoor Ali Khan Pataudi</a>, <a href=\"M.%20J.%20K.%20Smith\">M. J. K. Smith</a>, and <a href=\"Pelham%20Warner\">Pelham Warner</a>.\n",
            "[Document 3] : </li><li>- Mona Chong as a Chinese girl\n",
            "</li><li>- Sylvana Henriques as a Jamaican girl\n",
            "</li><li>- Dani Sheridan as an American girl\n",
            "</li><li>- <a href=\"Zaheera\">Zaheera</a> as Zara, an Indian girl\n",
            "</li><li>- Ingrit Back as a German girl\n",
            "</li><li>- Helena Ronee as an Israeli girl\n",
            "</li></ul>\n",
            "\n",
            "\n",
            ">> Thought: The provided documents do not seem to contain information about the cast members of Wowowin and Bubble Gang, which are Philippine TV shows. The documents appear to be unrelated to the topic.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Cast members of Wowowin and Bubble Gang, Philippine TV shows\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Cast members of Wowowin and Bubble Gang, Philippine TV shows\n",
            "[DEBUG] Observation: [Document 1] : Founder.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a>\n",
            "</li><li>- <a href=\"Reckless%20Youth\">Reckless Youth</a>\n",
            "</li></ul>\n",
            "Owner.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2002–present)\n",
            "</li><li>- The Titor Conglomerate (storyline) (2010–2013)\n",
            "</li><li>- <a href=\"Robbie%20Ellis\">Robbie Ellis</a> (storyline) (2014–present)\n",
            "</li></ul>\n",
            "Commissioner.<ul><li>- <a href=\"Bob%20Saget\">Bob Saget</a> (2006–2008)\n",
            "</li><li>- <a href=\"Dave%20Coulier\">Dave Coulier</a> (2008–2010)\n",
            "</li></ul>\n",
            "Director of Fun.<ul><li>- Leonard F. Chikarason (2005–2009)\n",
            "</li><li>- <a href=\"Dieter%20VonSteigerwalt\">Dieter VonSteigerwalt</a> (2009–2010)\n",
            "</li><li>- Wink Vavasseur (2010–2013)\n",
            "</li><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2014–2017)\n",
            "</li><li>- Bryce Remsburg – acting/interim director of Fun (2016)\n",
            "</li><li>- Bryce Remsburg (2017–present)\n",
            "</li></ul>\n",
            "[Document 2] : Ali Khan Pataudi</a>, <a href=\"Mansoor%20Ali%20Khan%20Pataudi\">Mansoor Ali Khan Pataudi</a>, <a href=\"M.%20J.%20K.%20Smith\">M. J. K. Smith</a>, and <a href=\"Pelham%20Warner\">Pelham Warner</a>.\n",
            "[Document 3] : </li><li>- Mona Chong as a Chinese girl\n",
            "</li><li>- Sylvana Henriques as a Jamaican girl\n",
            "</li><li>- Dani Sheridan as an American girl\n",
            "</li><li>- <a href=\"Zaheera\">Zaheera</a> as Zara, an Indian girl\n",
            "</li><li>- Ingrit Back as a German girl\n",
            "</li><li>- Helena Ronee as an Israeli girl\n",
            "</li></ul>\n",
            "\n",
            "\n",
            ">> Thought: I need to find information about the cast members of Wowowin and Bubble Gang to determine if they have any common cast members.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Cast members of Wowowin and Bubble Gang, Philippine TV shows\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Cast members of Wowowin and Bubble Gang, Philippine TV shows\n",
            "[DEBUG] Observation: [Document 1] : Founder.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a>\n",
            "</li><li>- <a href=\"Reckless%20Youth\">Reckless Youth</a>\n",
            "</li></ul>\n",
            "Owner.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2002–present)\n",
            "</li><li>- The Titor Conglomerate (storyline) (2010–2013)\n",
            "</li><li>- <a href=\"Robbie%20Ellis\">Robbie Ellis</a> (storyline) (2014–present)\n",
            "</li></ul>\n",
            "Commissioner.<ul><li>- <a href=\"Bob%20Saget\">Bob Saget</a> (2006–2008)\n",
            "</li><li>- <a href=\"Dave%20Coulier\">Dave Coulier</a> (2008–2010)\n",
            "</li></ul>\n",
            "Director of Fun.<ul><li>- Leonard F. Chikarason (2005–2009)\n",
            "</li><li>- <a href=\"Dieter%20VonSteigerwalt\">Dieter VonSteigerwalt</a> (2009–2010)\n",
            "</li><li>- Wink Vavasseur (2010–2013)\n",
            "</li><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2014–2017)\n",
            "</li><li>- Bryce Remsburg – acting/interim director of Fun (2016)\n",
            "</li><li>- Bryce Remsburg (2017–present)\n",
            "</li></ul>\n",
            "[Document 2] : Ali Khan Pataudi</a>, <a href=\"Mansoor%20Ali%20Khan%20Pataudi\">Mansoor Ali Khan Pataudi</a>, <a href=\"M.%20J.%20K.%20Smith\">M. J. K. Smith</a>, and <a href=\"Pelham%20Warner\">Pelham Warner</a>.\n",
            "[Document 3] : </li><li>- Mona Chong as a Chinese girl\n",
            "</li><li>- Sylvana Henriques as a Jamaican girl\n",
            "</li><li>- Dani Sheridan as an American girl\n",
            "</li><li>- <a href=\"Zaheera\">Zaheera</a> as Zara, an Indian girl\n",
            "</li><li>- Ingrit Back as a German girl\n",
            "</li><li>- Helena Ronee as an Israeli girl\n",
            "</li></ul>\n",
            "\n",
            "\n",
            ">> Thought: I need to find information about the cast members of Wowowin and Bubble Gang to determine if they have any common cast members.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Cast members of Wowowin and Bubble Gang, Philippine TV shows\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Cast members of Wowowin and Bubble Gang, Philippine TV shows\n",
            "[DEBUG] Observation: [Document 1] : Founder.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a>\n",
            "</li><li>- <a href=\"Reckless%20Youth\">Reckless Youth</a>\n",
            "</li></ul>\n",
            "Owner.<ul><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2002–present)\n",
            "</li><li>- The Titor Conglomerate (storyline) (2010–2013)\n",
            "</li><li>- <a href=\"Robbie%20Ellis\">Robbie Ellis</a> (storyline) (2014–present)\n",
            "</li></ul>\n",
            "Commissioner.<ul><li>- <a href=\"Bob%20Saget\">Bob Saget</a> (2006–2008)\n",
            "</li><li>- <a href=\"Dave%20Coulier\">Dave Coulier</a> (2008–2010)\n",
            "</li></ul>\n",
            "Director of Fun.<ul><li>- Leonard F. Chikarason (2005–2009)\n",
            "</li><li>- <a href=\"Dieter%20VonSteigerwalt\">Dieter VonSteigerwalt</a> (2009–2010)\n",
            "</li><li>- Wink Vavasseur (2010–2013)\n",
            "</li><li>- <a href=\"Mike%20Quackenbush\">Mike Quackenbush</a> (2014–2017)\n",
            "</li><li>- Bryce Remsburg – acting/interim director of Fun (2016)\n",
            "</li><li>- Bryce Remsburg (2017–present)\n",
            "</li></ul>\n",
            "[Document 2] : Ali Khan Pataudi</a>, <a href=\"Mansoor%20Ali%20Khan%20Pataudi\">Mansoor Ali Khan Pataudi</a>, <a href=\"M.%20J.%20K.%20Smith\">M. J. K. Smith</a>, and <a href=\"Pelham%20Warner\">Pelham Warner</a>.\n",
            "[Document 3] : </li><li>- Mona Chong as a Chinese girl\n",
            "</li><li>- Sylvana Henriques as a Jamaican girl\n",
            "</li><li>- Dani Sheridan as an American girl\n",
            "</li><li>- <a href=\"Zaheera\">Zaheera</a> as Zara, an Indian girl\n",
            "</li><li>- Ingrit Back as a German girl\n",
            "</li><li>- Helena Ronee as an Israeli girl\n",
            "</li></ul>\n",
            "\n",
            "Maximum number of steps reached. Stopping.\n",
            "Question: [2/2]\n",
            "\n",
            "\n",
            "\n",
            "==================================================\n",
            "[DEBUG] Question: Who owned the Rochester Rhinos when Glenn left the team?\n",
            "\n",
            ">> Thought: I need more information about the Rochester Rhinos and Glenn to answer this question.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Rochester Rhinos ownership history\" and \"Glenn's departure from the team\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Rochester Rhinos ownership history\n",
            "[DEBUG] Observation: [Document 1] : The team was declared insolvent in 2008 after defaulting on their stadium agreement, and PAETEC Park was seized by the city of Rochester. After a brief search for a new owner and investor who could improve the team's financial outlook, in March 2008 the club was taken over by <a href=\"Utica%2C%20New%20York\">Utica</a> businessman Rob Clark. Clark changed the team's name to the \"Rochester Rhinos,\" and assured that the financial situation of the team was stable and it would be able to play the next year. After two seasons under Clark the club joined the <a href=\"North%20American%20Soccer%20League\">new NASL</a> for its 2010 season. The <a href=\"United%20States%20Soccer%20Federation\">United States Soccer Federation</a> refused the NASL's application for sanctioning, and instead operated its own temporary second-division league for 2010. The Rhinos were part of that temporary <a href=\"USSF%20Division%202%20Professional%20League\">USSF Division 2 Professional League</a> league. The Rhinos\n",
            "[Document 2] : Notable former players.<ul><li>- <i>See also <a href=\"All-time%20Rochester%20Rhinos%20roster\">All-time Rochester Rhinos roster</a></i>\n",
            "</li></ul>\n",
            "Rochester Rhinos Hall of Fame.<ul><li>- 2011: <a href=\"Lenin%20Steenkamp\">Lenin Steenkamp</a>\n",
            "</li><li>- 2012: <a href=\"Craig%20Demmin\">Craig Demmin</a>, <a href=\"Doug%20Miller%20%28soccer%29\">Doug Miller</a>, <a href=\"Pat%20Onstad\">Pat Onstad</a>\n",
            "</li><li>- 2013: <a href=\"1999%20U.S.%20Open%20Cup\">1999 U.S. Open Cup</a> Team\n",
            "</li><li>- 2014: <a href=\"Yari%20Allnutt\">Yari Allnutt</a>, <a href=\"Scott%20Vallow\">Scott Vallow</a>\n",
            "</li><li>- 2015: <a href=\"Darren%20Tilley\">Darren Tilley</a>, <a href=\"Mali%20Walton\">Mali Walton</a>\n",
            "</li></ul>\n",
            "Retired numbers.<ul><li>- 19 – <a href=\"Doug%20Miller%20%28soccer%29\">Doug Miller</a>\n",
            "</li></ul>\n",
            "Head coaches.<ul><li>- <a href=\"Pat%20Ercoli\">Pat Ercoli</a> (1996–2004)\n",
            "</li><li>- <a href=\"Laurie%20Calloway\">Laurie Calloway</a> (2005–2007)\n",
            "</li><li>- <a href=\"Darren%20Tilley\">Darren Tilley</a> (2008–2009)\n",
            "[Document 3] : The Rochester Rhinos are an American professional <a href=\"association%20football\">soccer</a> team based in <a href=\"Rochester%2C%20New%20York\">Rochester, New York</a>, United States. Founded in 1996, as the Rochester Raging Rhinos, the team formerly played in the <a href=\"United%20Soccer%20League\">United Soccer League</a> in the second tier of the <a href=\"United%20States%20soccer%20league%20system\">United States soccer league system</a>, and is currently on hiatus. They changed their name to Rochester Rhinos to start the 2008 season. The club is the only non-MLS team to have won the <a href=\"U.S.%20Open%20Cup\">U.S. Open Cup</a> since the league's formation.\n",
            "\n",
            "On November 30, 2017, the team announced that they would not play in 2018 while additional funding was sought.\n",
            "\n",
            "On August 22, 2018, it was announced that the club will pursue a new stadium location and join <a href=\"USL%20League%20One\">USL League One</a> by the 2020 season.\n",
            "\n",
            "\n",
            ">> Thought: I have received the information about the Rochester Rhinos and can now answer the question.\n",
            "\n",
            "Action: Response To Question\n",
            "Response: Rob Clark\n",
            "[DEBUG] Action: response to question\n",
            "[DEBUG] Action Input: None\n",
            "[DEBUG] Response: Rob Clark\n",
            "Question: [1/2]\n",
            "\n",
            "\n",
            "\n",
            "==================================================\n",
            "[DEBUG] Question: Was George Metcalfe still alive when Moore was commissioned Justice of the Peace?\n",
            "\n",
            ">> Thought: I need to understand the context and determine what information is available to answer the question.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Information about George Metcalfe and Moore's commission as Justice of the Peace\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Information about George Metcalfe and Moore's commission as Justice of the Peace\n",
            "[DEBUG] Observation: [Document 1] : On January 20, 1899, President McKinley appointed <a href=\"Jacob%20Gould%20Schurman\">Jacob Gould Schurman</a> to chair a <a href=\"Schurman%20Commission\">commission</a>, with <a href=\"Dean%20C.%20Worcester\">Dean C. Worcester</a>, <a href=\"Charles%20Harvey%20Denby\">Charles H. Denby</a>, Admiral Dewey, and General Otis as members, to investigate conditions in the islands and make recommendations. Fighting subsequently erupted between U.S. and Filipino forces on February 4, and when the non-military commission members arrived in the Philippines in March, they found General Otis looking upon the commission as an infringement upon his authority.\n",
            "[Document 2] : Briggs</a>; retired Justices include <a href=\"David%20Neuberger%2C%20Baron%20Neuberger%20of%20Abbotsbury\">David Neuberger</a> (President of the Supreme Court 2012–2017), <a href=\"Jonathan%20Mance%2C%20Baron%20Mance\">Jonathan Mance</a> (Deputy President of the Supreme Court 2017–2018), <a href=\"Alan%20Rodger%2C%20Baron%20Rodger%20of%20Earlsferry\">Alan Rodger</a>, <a href=\"Jonathan%20Sumption%2C%20Lord%20Sumption\">Jonathan Sumption</a>, <a href=\"Mark%20Saville%2C%20Baron%20Saville%20of%20Newdigate\">Mark Saville,</a> <a href=\"John%20Dyson%2C%20Lord%20Dyson\">John Dyson</a>, and <a href=\"Simon%20Brown%2C%20Baron%20Brown%20of%20Eaton-under-Heywood\">Simon Brown</a>. The twelve <a href=\"Lord%20Chancellor\">Lord Chancellors</a> and nine <a href=\"Lord%20Chief%20Justice%20of%20England%20and%20Wales\">Lord Chief Justices</a> that have been educated at Oxford include <a href=\"Thomas%20Bingham%2C%20Baron%20Bingham%20of%20Cornhill\">Thomas Bingham</a>, <a\n",
            "[Document 3] : Grant's administration had limited success with civil service reform. Grant's Secretary of Interior <a href=\"Jacob%20D.%20Cox\">Jacob D. Cox</a> fired unqualified clerks, implemented a merit testing system, and rebuffed mandatory party contributions. On October 3, 1870, Cox resigned office under a dispute with Grant over the McGarrahan claim. On March 3, 1871 Congress authorized Grant to create the <a href=\"United%20States%20Civil%20Service%20Commission\">Civil Service Commission</a>. Grant appointed reformer <a href=\"George%20William%20Curtis\">George William Curtis</a> to head of the Commission, that advocated competitive exams, and the end of forced political payments. The Commission's rules took effect the next year, but Department heads, assistants, and higher level officials were exempted.\n",
            "\n",
            "\n",
            ">> Thought: I have received the context information, but it does not provide direct information about George Metcalfe and Moore's commission as Justice of the Peace. I need to ask for more information or clarification.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\n",
            "[DEBUG] Observation: [Document 1] : On 8 November, <a href=\"Charles%20Warren\">Charles Warren</a> resigned as <a href=\"Commissioner%20of%20Police%20of%20the%20Metropolis\">Commissioner of the Metropolitan Police</a> after the <a href=\"Home%20Secretary\">Home Secretary</a> informed him that he could not make public statements without Home Office approval. <a href=\"James%20Monro\">James Monro</a>, who had resigned a few months earlier over differences with Warren, was appointed as his replacement in December. On 10 November, the police surgeon <a href=\"Thomas%20Bond%20%28British%20physician%29\">Thomas Bond</a> wrote to <a href=\"Robert%20Anderson%20%28police%20official%29\">Robert Anderson</a>, head of the London CID, detailing the similarities between the five murders of Nichols, Chapman, Stride, Eddowes and Kelly, \"no doubt committed by the same hand\". On the same day, the <a href=\"Cabinet%20of%20the%20United%20Kingdom\">Cabinet</a> resolved to offer a pardon to any accomplice who came forward with information that led to the\n",
            "[Document 2] : In autumn 1972, <a href=\"Frank%20Pakenham%2C%207th%20Earl%20of%20Longford\">Lord Longford</a> and <a href=\"Raymond%20Blackburn\">Raymond Blackburn</a> decided to pursue a matter of pornography classification for the film <i><a href=\"Language%20of%20Love\">Language of Love</a></i> into the <a href=\"Court%20of%20Appeal\">Court of Appeal</a> of <a href=\"Lord%20Denning\">Lord Denning</a>, MR, and lost the writ of <a href=\"mandamus\">mandamus</a> against the Police Commissioner, who had refused to intrude upon the BBFC remit.\n",
            "[Document 3] : The <a href=\"positivist\">positivist</a> historian <a href=\"Edward%20Spencer%20Beesly\">Edward Spencer Beesly</a>, a professor at <a href=\"London%20University\">London University</a>, was in the chair. His speech pilloried the violent proceedings of the governments and referred to their flagrant breaches of <a href=\"international%20law\">international law</a> and advocated a union of the workers of the world for the realisation of justice on earth. <a href=\"George%20Odger\">George Odger</a>, Secretary of the <a href=\"London%20Trades%20Council\">London Trades Council</a>, read a speech calling for international co-operation.\n",
            "\n",
            "\n",
            ">> Thought: I have received the context information, but it does not provide direct information about George Metcalfe and Moore's commission as Justice of the Peace. I need to ask for more information or clarification.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\n",
            "[DEBUG] Observation: [Document 1] : On 8 November, <a href=\"Charles%20Warren\">Charles Warren</a> resigned as <a href=\"Commissioner%20of%20Police%20of%20the%20Metropolis\">Commissioner of the Metropolitan Police</a> after the <a href=\"Home%20Secretary\">Home Secretary</a> informed him that he could not make public statements without Home Office approval. <a href=\"James%20Monro\">James Monro</a>, who had resigned a few months earlier over differences with Warren, was appointed as his replacement in December. On 10 November, the police surgeon <a href=\"Thomas%20Bond%20%28British%20physician%29\">Thomas Bond</a> wrote to <a href=\"Robert%20Anderson%20%28police%20official%29\">Robert Anderson</a>, head of the London CID, detailing the similarities between the five murders of Nichols, Chapman, Stride, Eddowes and Kelly, \"no doubt committed by the same hand\". On the same day, the <a href=\"Cabinet%20of%20the%20United%20Kingdom\">Cabinet</a> resolved to offer a pardon to any accomplice who came forward with information that led to the\n",
            "[Document 2] : In autumn 1972, <a href=\"Frank%20Pakenham%2C%207th%20Earl%20of%20Longford\">Lord Longford</a> and <a href=\"Raymond%20Blackburn\">Raymond Blackburn</a> decided to pursue a matter of pornography classification for the film <i><a href=\"Language%20of%20Love\">Language of Love</a></i> into the <a href=\"Court%20of%20Appeal\">Court of Appeal</a> of <a href=\"Lord%20Denning\">Lord Denning</a>, MR, and lost the writ of <a href=\"mandamus\">mandamus</a> against the Police Commissioner, who had refused to intrude upon the BBFC remit.\n",
            "[Document 3] : The <a href=\"positivist\">positivist</a> historian <a href=\"Edward%20Spencer%20Beesly\">Edward Spencer Beesly</a>, a professor at <a href=\"London%20University\">London University</a>, was in the chair. His speech pilloried the violent proceedings of the governments and referred to their flagrant breaches of <a href=\"international%20law\">international law</a> and advocated a union of the workers of the world for the realisation of justice on earth. <a href=\"George%20Odger\">George Odger</a>, Secretary of the <a href=\"London%20Trades%20Council\">London Trades Council</a>, read a speech calling for international co-operation.\n",
            "\n",
            "\n",
            ">> Thought: I have received the context information, but it does not provide direct information about George Metcalfe and Moore's commission as Justice of the Peace. I need to ask for more information or clarification.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\n",
            "[DEBUG] Observation: [Document 1] : On 8 November, <a href=\"Charles%20Warren\">Charles Warren</a> resigned as <a href=\"Commissioner%20of%20Police%20of%20the%20Metropolis\">Commissioner of the Metropolitan Police</a> after the <a href=\"Home%20Secretary\">Home Secretary</a> informed him that he could not make public statements without Home Office approval. <a href=\"James%20Monro\">James Monro</a>, who had resigned a few months earlier over differences with Warren, was appointed as his replacement in December. On 10 November, the police surgeon <a href=\"Thomas%20Bond%20%28British%20physician%29\">Thomas Bond</a> wrote to <a href=\"Robert%20Anderson%20%28police%20official%29\">Robert Anderson</a>, head of the London CID, detailing the similarities between the five murders of Nichols, Chapman, Stride, Eddowes and Kelly, \"no doubt committed by the same hand\". On the same day, the <a href=\"Cabinet%20of%20the%20United%20Kingdom\">Cabinet</a> resolved to offer a pardon to any accomplice who came forward with information that led to the\n",
            "[Document 2] : In autumn 1972, <a href=\"Frank%20Pakenham%2C%207th%20Earl%20of%20Longford\">Lord Longford</a> and <a href=\"Raymond%20Blackburn\">Raymond Blackburn</a> decided to pursue a matter of pornography classification for the film <i><a href=\"Language%20of%20Love\">Language of Love</a></i> into the <a href=\"Court%20of%20Appeal\">Court of Appeal</a> of <a href=\"Lord%20Denning\">Lord Denning</a>, MR, and lost the writ of <a href=\"mandamus\">mandamus</a> against the Police Commissioner, who had refused to intrude upon the BBFC remit.\n",
            "[Document 3] : The <a href=\"positivist\">positivist</a> historian <a href=\"Edward%20Spencer%20Beesly\">Edward Spencer Beesly</a>, a professor at <a href=\"London%20University\">London University</a>, was in the chair. His speech pilloried the violent proceedings of the governments and referred to their flagrant breaches of <a href=\"international%20law\">international law</a> and advocated a union of the workers of the world for the realisation of justice on earth. <a href=\"George%20Odger\">George Odger</a>, Secretary of the <a href=\"London%20Trades%20Council\">London Trades Council</a>, read a speech calling for international co-operation.\n",
            "\n",
            "\n",
            ">> Thought: I have received the context information, but it does not provide direct information about George Metcalfe and Moore's commission as Justice of the Peace. I need to ask for more information or clarification.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: More information about George Metcalfe and Moore's commission as Justice of the Peace, or clarification on the context\n",
            "[DEBUG] Observation: [Document 1] : On 8 November, <a href=\"Charles%20Warren\">Charles Warren</a> resigned as <a href=\"Commissioner%20of%20Police%20of%20the%20Metropolis\">Commissioner of the Metropolitan Police</a> after the <a href=\"Home%20Secretary\">Home Secretary</a> informed him that he could not make public statements without Home Office approval. <a href=\"James%20Monro\">James Monro</a>, who had resigned a few months earlier over differences with Warren, was appointed as his replacement in December. On 10 November, the police surgeon <a href=\"Thomas%20Bond%20%28British%20physician%29\">Thomas Bond</a> wrote to <a href=\"Robert%20Anderson%20%28police%20official%29\">Robert Anderson</a>, head of the London CID, detailing the similarities between the five murders of Nichols, Chapman, Stride, Eddowes and Kelly, \"no doubt committed by the same hand\". On the same day, the <a href=\"Cabinet%20of%20the%20United%20Kingdom\">Cabinet</a> resolved to offer a pardon to any accomplice who came forward with information that led to the\n",
            "[Document 2] : In autumn 1972, <a href=\"Frank%20Pakenham%2C%207th%20Earl%20of%20Longford\">Lord Longford</a> and <a href=\"Raymond%20Blackburn\">Raymond Blackburn</a> decided to pursue a matter of pornography classification for the film <i><a href=\"Language%20of%20Love\">Language of Love</a></i> into the <a href=\"Court%20of%20Appeal\">Court of Appeal</a> of <a href=\"Lord%20Denning\">Lord Denning</a>, MR, and lost the writ of <a href=\"mandamus\">mandamus</a> against the Police Commissioner, who had refused to intrude upon the BBFC remit.\n",
            "[Document 3] : The <a href=\"positivist\">positivist</a> historian <a href=\"Edward%20Spencer%20Beesly\">Edward Spencer Beesly</a>, a professor at <a href=\"London%20University\">London University</a>, was in the chair. His speech pilloried the violent proceedings of the governments and referred to their flagrant breaches of <a href=\"international%20law\">international law</a> and advocated a union of the workers of the world for the realisation of justice on earth. <a href=\"George%20Odger\">George Odger</a>, Secretary of the <a href=\"London%20Trades%20Council\">London Trades Council</a>, read a speech calling for international co-operation.\n",
            "\n",
            "Maximum number of steps reached. Stopping.\n",
            "Question: [2/2]\n",
            "\n",
            "\n",
            "\n",
            "==================================================\n",
            "[DEBUG] Question: Who were the members of the band that inspired Tom Robinson to found a band in 1976?\n",
            "\n",
            ">> Thought: I need to find out which band inspired Tom Robinson to found a band in 1976.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"bands that inspired Tom Robinson to form a band in 1976\"\n",
            "\n",
            "Please respond with the observation.\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: bands that inspired Tom Robinson to form a band in 1976\n",
            "[DEBUG] Observation: [Document 1] : 1976–1979.Starting in 1976, following recent releases of recordings by punk bands such as the <a href=\"Ramones\">Ramones</a>, a number of punk bands formed in the Los Angeles and Orange County area. Among these bands were <a href=\"Germs%20%28band%29\">the Germs</a>, <a href=\"the%20Flesh%20Eaters\">the Flesh Eaters</a>, <a href=\"the%20Weirdos\">the Weirdos</a>, <a href=\"The%20Controllers%20%28band%29\">the Controllers</a>, the Deadbeats, <a href=\"The%20Skulls%20%28American%20band%29\">the Skulls</a>, the <a href=\"Angry%20Samoans\">Angry Samoans</a>, <a href=\"Agent%20Orange%20%28band%29\">Agent Orange</a>, <a href=\"the%20Dils\">the Dils</a>, <a href=\"Black%20Randy%20and%20the%20Metrosquad\">Black Randy and the Metrosquad</a>, <a href=\"Catholic%20Discipline\">Catholic Discipline</a>, <a href=\"the%20Go-Go%27s\">the Go-Go's</a>, <a href=\"The%20Alley%20Cats%20%28Los%20Angeles%20punk%20band%29\">the Alley Cats</a>, <a href=\"Kommunity%20FK\">Kommunity FK</a>, <a href=\"the%20Screamers\">the Screamers</a>, <a\n",
            "[Document 2] : In the late 1980s the Bay Area punk scene began to flourish. In 1987, Matt Freeman and Tim Armstrong (future members of <a href=\"Rancid%20%28band%29\">Rancid</a>) started ska-punk band <a href=\"Operation%20Ivy\">Operation Ivy</a>. Other Bay Area bands were <a href=\"Mr.%20T%20Experience\">Mr. T Experience</a>, <a href=\"Isocracy\">Isocracy</a>, <a href=\"Samiam\">Samiam</a>, and <a href=\"Crimpshrine\">Crimpshrine</a>. Over the next 20 years the Bay Area punk scene formed such influential punk bands such as <a href=\"Swingin%20Utters\">Swingin Utters</a>, <a href=\"Rancid%20%28band%29\">Rancid</a>, <a href=\"One%20Man%20Army%20%28band%29\">One Man Army</a>, <a href=\"The%20Forgotten%20%28band%29\">the Forgotten</a>, <a href=\"AFI%20%28band%29\">AFI</a>, <a href=\"Screaming%20Bloody%20Marys\">Screaming Bloody Marys</a> on record labels such as Sympathy for the Record Industry and <a href=\"Dead%20to%20Me%20%28band%29\">Dead to Me</a>.\n",
            "[Document 3] : Records</a> (formed in December 1978 when <a href=\"Ray%20Caviano\">Ray Caviano</a> became the executive director of Warner's disco division), and <a href=\"Tom%20Silverman\">Tom Silverman</a>'s <a href=\"Tommy%20Boy%20Records\">Tommy Boy Records</a> (another label Warner Bros. eventually took over).\n",
            "\n",
            "\n",
            ">> Thought: I need to find the band that inspired Tom Robinson to found a band in 1976.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"bands that inspired Tom Robinson to form a band in 1976, specifically the Ramones\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: bands that inspired Tom Robinson to form a band in 1976, specifically the Ramones\n",
            "[DEBUG] Observation: [Document 1] : 1976–1979.Starting in 1976, following recent releases of recordings by punk bands such as the <a href=\"Ramones\">Ramones</a>, a number of punk bands formed in the Los Angeles and Orange County area. Among these bands were <a href=\"Germs%20%28band%29\">the Germs</a>, <a href=\"the%20Flesh%20Eaters\">the Flesh Eaters</a>, <a href=\"the%20Weirdos\">the Weirdos</a>, <a href=\"The%20Controllers%20%28band%29\">the Controllers</a>, the Deadbeats, <a href=\"The%20Skulls%20%28American%20band%29\">the Skulls</a>, the <a href=\"Angry%20Samoans\">Angry Samoans</a>, <a href=\"Agent%20Orange%20%28band%29\">Agent Orange</a>, <a href=\"the%20Dils\">the Dils</a>, <a href=\"Black%20Randy%20and%20the%20Metrosquad\">Black Randy and the Metrosquad</a>, <a href=\"Catholic%20Discipline\">Catholic Discipline</a>, <a href=\"the%20Go-Go%27s\">the Go-Go's</a>, <a href=\"The%20Alley%20Cats%20%28Los%20Angeles%20punk%20band%29\">the Alley Cats</a>, <a href=\"Kommunity%20FK\">Kommunity FK</a>, <a href=\"the%20Screamers\">the Screamers</a>, <a\n",
            "[Document 2] : Origins (1974–1979).<a href=\"Protopunk\">Protopunk</a> and <a href=\"power%20pop\">power pop</a> bands of the late 1960s and early 1970s helped lay the groundwork for the pop punk sound, which emerged at the onset of <a href=\"punk%20rock\">punk rock</a> around 1974 with the <a href=\"Ramones\">Ramones</a>. <a href=\"The%20Beatles\">The Beatles</a>, <a href=\"the%20Kinks\">the Kinks</a> and <a href=\"the%20Beach%20Boys\">the Beach Boys</a> all paved the way for pop punk. With their love of <a href=\"the%20Beach%20Boys\">the Beach Boys</a> and late 1960s <a href=\"bubblegum%20pop\">bubblegum pop</a>, the Ramones paved the way to what became known as pop punk. The Ramones' loud and fast melodic minimalism differentiated them from other bands in New York City's budding <a href=\"art%20rock\">art rock</a> scene, but pop punk was not considered a separate subgenre until later. An early use of the term \"pop punk\" appeared in a 1977 <i><a href=\"New%20York%20Times\">New York Times</a></i> article, \"Cabaret: <a\n",
            "[Document 3] : Pre-1976.Los Angeles had a very strong <a href=\"glam%20rock\">glam rock</a> scene in the early 1970s, mostly centered on the club <a href=\"Rodney%20Bingenheimer%27s%20English%20Disco\">Rodney Bingenheimer's English Disco</a>, run by <a href=\"Rodney%20Bingenheimer\">Rodney Bingenheimer</a>, who later, as a <a href=\"disc%20jockey\">disc jockey</a> for <a href=\"KROQ-FM\">KROQ's</a> <i>Rodney on the ROQ</i>, did much to promote LA punk bands. Many figures from this earlier scene would play notable roles in the later punk scene.\n",
            "\n",
            "In the mid-1970s from 1974 to 1975 a wave of <a href=\"proto-punk\">proto-punk</a> bands emerged from Los Angeles, including the <a href=\"Flyboys%20%28band%29\">Flyboys</a> and Atomic Kid.\n",
            "\n",
            "\n",
            ">> Thought: I need to find the members of the Ramones, the band that inspired Tom Robinson to found a band in 1976.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"members of the Ramones\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: members of the Ramones\n",
            "[DEBUG] Observation: [Document 1] : Band members.<ul><li>- Current members\n",
            "</li><li>- <a href=\"Mike%20Muir\">Mike \"Cyco Miko\" Muir</a> – <a href=\"Lead%20vocalist\">lead vocals</a> (1980–present)\n",
            "</li><li>- <a href=\"Dean%20Pleasants\">Dean Pleasants</a> – <a href=\"lead%20guitar\">lead guitar</a>, <a href=\"Backing%20vocalist\">backing vocals</a> (1996–present)\n",
            "</li><li>- <a href=\"Dave%20Lombardo\">Dave Lombardo</a> – <a href=\"Drum%20kit\">drums</a> (2016–present)\n",
            "</li><li>- Ra Díaz – <a href=\"Bass%20guitar\">bass</a>, backing vocals (2016–present)\n",
            "</li><li>- <a href=\"Ben%20Weinman\">Ben Weinman</a> – <a href=\"rhythm%20guitar\">rhythm guitar</a> (2018–present)\n",
            "</li></ul>\n",
            "Discography.<ul><li>- <i><a href=\"Suicidal%20Tendencies%20%28album%29\">Suicidal Tendencies</a></i> (1983)\n",
            "</li><li>- <i><a href=\"Join%20the%20Army\">Join the Army</a></i> (1987)\n",
            "</li><li>- <i><a href=\"How%20Will%20I%20Laugh%20Tomorrow%20When%20I%20Can%27t%20Even%20Smile%20Today\">How Will I Laugh Tomorrow When I Can't Even Smile Today</a></i> (1988)\n",
            "[Document 2] : trio</a> also featuring bassist <a href=\"Billy%20Sheehan\">Billy Sheehan</a> (<a href=\"Mr.%20Big%20%28band%29\">Mr. Big</a>) and guitarist <a href=\"Richie%20Kotzen\">Richie Kotzen</a> (formerly of Mr. Big and <a href=\"Poison%20%28American%20band%29\">Poison</a>), and <a href=\"Sons%20of%20Apollo\">Sons of Apollo</a>, a progressive metal supergroup also featuring Sheehan, <a href=\"Derek%20Sherinian\">Derek Sherinian</a>, <a href=\"Jeff%20Scott%20Soto\">Jeff Scott Soto</a> and <a href=\"Ron%20%26quot%3BBumblefoot%26quot%3B%20Thal\">Ron \"Bumblefoot\" Thal</a>.\n",
            "[Document 3] : Band members.Current members\n",
            "<ul><li>- <a href=\"John%20Petrucci\">John Petrucci</a> – guitars , backing vocals\n",
            "</li><li>- <a href=\"John%20Myung\">John Myung</a> – bass\n",
            "</li><li>- <a href=\"James%20LaBrie\">James LaBrie</a> – lead vocals\n",
            "</li><li>- <a href=\"Jordan%20Rudess\">Jordan Rudess</a> – keyboards, piano\n",
            "</li><li>- <a href=\"Mike%20Mangini\">Mike Mangini</a> – drums, percussion\n",
            "</li></ul>\n",
            "Former members\n",
            "<ul><li>- <a href=\"Chris%20Collins%20%28singer%29\">Chris Collins</a> – lead vocals\n",
            "</li><li>- <a href=\"Kevin%20Moore\">Kevin Moore</a> – keyboards, piano\n",
            "</li><li>- <a href=\"Mike%20Portnoy\">Mike Portnoy</a> – drums, percussion , backing vocals\n",
            "</li><li>- <a href=\"Charlie%20Dominici\">Charlie Dominici</a> – lead vocals\n",
            "</li><li>- <a href=\"Derek%20Sherinian\">Derek Sherinian</a> – keyboards , backing vocals\n",
            "</li></ul>Timeline\n",
            "Notes\n",
            "\n",
            "\n",
            ">> Thought: I need to find the members of the Ramones, the band that inspired Tom Robinson to form a band in 1976.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"members of the Ramones\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: members of the Ramones\n",
            "[DEBUG] Observation: [Document 1] : Band members.<ul><li>- Current members\n",
            "</li><li>- <a href=\"Mike%20Muir\">Mike \"Cyco Miko\" Muir</a> – <a href=\"Lead%20vocalist\">lead vocals</a> (1980–present)\n",
            "</li><li>- <a href=\"Dean%20Pleasants\">Dean Pleasants</a> – <a href=\"lead%20guitar\">lead guitar</a>, <a href=\"Backing%20vocalist\">backing vocals</a> (1996–present)\n",
            "</li><li>- <a href=\"Dave%20Lombardo\">Dave Lombardo</a> – <a href=\"Drum%20kit\">drums</a> (2016–present)\n",
            "</li><li>- Ra Díaz – <a href=\"Bass%20guitar\">bass</a>, backing vocals (2016–present)\n",
            "</li><li>- <a href=\"Ben%20Weinman\">Ben Weinman</a> – <a href=\"rhythm%20guitar\">rhythm guitar</a> (2018–present)\n",
            "</li></ul>\n",
            "Discography.<ul><li>- <i><a href=\"Suicidal%20Tendencies%20%28album%29\">Suicidal Tendencies</a></i> (1983)\n",
            "</li><li>- <i><a href=\"Join%20the%20Army\">Join the Army</a></i> (1987)\n",
            "</li><li>- <i><a href=\"How%20Will%20I%20Laugh%20Tomorrow%20When%20I%20Can%27t%20Even%20Smile%20Today\">How Will I Laugh Tomorrow When I Can't Even Smile Today</a></i> (1988)\n",
            "[Document 2] : trio</a> also featuring bassist <a href=\"Billy%20Sheehan\">Billy Sheehan</a> (<a href=\"Mr.%20Big%20%28band%29\">Mr. Big</a>) and guitarist <a href=\"Richie%20Kotzen\">Richie Kotzen</a> (formerly of Mr. Big and <a href=\"Poison%20%28American%20band%29\">Poison</a>), and <a href=\"Sons%20of%20Apollo\">Sons of Apollo</a>, a progressive metal supergroup also featuring Sheehan, <a href=\"Derek%20Sherinian\">Derek Sherinian</a>, <a href=\"Jeff%20Scott%20Soto\">Jeff Scott Soto</a> and <a href=\"Ron%20%26quot%3BBumblefoot%26quot%3B%20Thal\">Ron \"Bumblefoot\" Thal</a>.\n",
            "[Document 3] : Band members.Current members\n",
            "<ul><li>- <a href=\"John%20Petrucci\">John Petrucci</a> – guitars , backing vocals\n",
            "</li><li>- <a href=\"John%20Myung\">John Myung</a> – bass\n",
            "</li><li>- <a href=\"James%20LaBrie\">James LaBrie</a> – lead vocals\n",
            "</li><li>- <a href=\"Jordan%20Rudess\">Jordan Rudess</a> – keyboards, piano\n",
            "</li><li>- <a href=\"Mike%20Mangini\">Mike Mangini</a> – drums, percussion\n",
            "</li></ul>\n",
            "Former members\n",
            "<ul><li>- <a href=\"Chris%20Collins%20%28singer%29\">Chris Collins</a> – lead vocals\n",
            "</li><li>- <a href=\"Kevin%20Moore\">Kevin Moore</a> – keyboards, piano\n",
            "</li><li>- <a href=\"Mike%20Portnoy\">Mike Portnoy</a> – drums, percussion , backing vocals\n",
            "</li><li>- <a href=\"Charlie%20Dominici\">Charlie Dominici</a> – lead vocals\n",
            "</li><li>- <a href=\"Derek%20Sherinian\">Derek Sherinian</a> – keyboards , backing vocals\n",
            "</li></ul>Timeline\n",
            "Notes\n",
            "\n",
            "\n",
            ">> Thought: I need to find the members of the Ramones, the band that inspired Tom Robinson to form a band in 1976.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"members of the Ramones\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: members of the Ramones\n",
            "[DEBUG] Observation: [Document 1] : Band members.<ul><li>- Current members\n",
            "</li><li>- <a href=\"Mike%20Muir\">Mike \"Cyco Miko\" Muir</a> – <a href=\"Lead%20vocalist\">lead vocals</a> (1980–present)\n",
            "</li><li>- <a href=\"Dean%20Pleasants\">Dean Pleasants</a> – <a href=\"lead%20guitar\">lead guitar</a>, <a href=\"Backing%20vocalist\">backing vocals</a> (1996–present)\n",
            "</li><li>- <a href=\"Dave%20Lombardo\">Dave Lombardo</a> – <a href=\"Drum%20kit\">drums</a> (2016–present)\n",
            "</li><li>- Ra Díaz – <a href=\"Bass%20guitar\">bass</a>, backing vocals (2016–present)\n",
            "</li><li>- <a href=\"Ben%20Weinman\">Ben Weinman</a> – <a href=\"rhythm%20guitar\">rhythm guitar</a> (2018–present)\n",
            "</li></ul>\n",
            "Discography.<ul><li>- <i><a href=\"Suicidal%20Tendencies%20%28album%29\">Suicidal Tendencies</a></i> (1983)\n",
            "</li><li>- <i><a href=\"Join%20the%20Army\">Join the Army</a></i> (1987)\n",
            "</li><li>- <i><a href=\"How%20Will%20I%20Laugh%20Tomorrow%20When%20I%20Can%27t%20Even%20Smile%20Today\">How Will I Laugh Tomorrow When I Can't Even Smile Today</a></i> (1988)\n",
            "[Document 2] : trio</a> also featuring bassist <a href=\"Billy%20Sheehan\">Billy Sheehan</a> (<a href=\"Mr.%20Big%20%28band%29\">Mr. Big</a>) and guitarist <a href=\"Richie%20Kotzen\">Richie Kotzen</a> (formerly of Mr. Big and <a href=\"Poison%20%28American%20band%29\">Poison</a>), and <a href=\"Sons%20of%20Apollo\">Sons of Apollo</a>, a progressive metal supergroup also featuring Sheehan, <a href=\"Derek%20Sherinian\">Derek Sherinian</a>, <a href=\"Jeff%20Scott%20Soto\">Jeff Scott Soto</a> and <a href=\"Ron%20%26quot%3BBumblefoot%26quot%3B%20Thal\">Ron \"Bumblefoot\" Thal</a>.\n",
            "[Document 3] : Band members.Current members\n",
            "<ul><li>- <a href=\"John%20Petrucci\">John Petrucci</a> – guitars , backing vocals\n",
            "</li><li>- <a href=\"John%20Myung\">John Myung</a> – bass\n",
            "</li><li>- <a href=\"James%20LaBrie\">James LaBrie</a> – lead vocals\n",
            "</li><li>- <a href=\"Jordan%20Rudess\">Jordan Rudess</a> – keyboards, piano\n",
            "</li><li>- <a href=\"Mike%20Mangini\">Mike Mangini</a> – drums, percussion\n",
            "</li></ul>\n",
            "Former members\n",
            "<ul><li>- <a href=\"Chris%20Collins%20%28singer%29\">Chris Collins</a> – lead vocals\n",
            "</li><li>- <a href=\"Kevin%20Moore\">Kevin Moore</a> – keyboards, piano\n",
            "</li><li>- <a href=\"Mike%20Portnoy\">Mike Portnoy</a> – drums, percussion , backing vocals\n",
            "</li><li>- <a href=\"Charlie%20Dominici\">Charlie Dominici</a> – lead vocals\n",
            "</li><li>- <a href=\"Derek%20Sherinian\">Derek Sherinian</a> – keyboards , backing vocals\n",
            "</li></ul>Timeline\n",
            "Notes\n",
            "\n",
            "Maximum number of steps reached. Stopping.\n",
            "Question: [1/1]\n",
            "\n",
            "\n",
            "\n",
            "==================================================\n",
            "[DEBUG] Question: In which country was Wilhelm Müller born?\n",
            "\n",
            ">> Thought: I need to find information about Wilhelm Müller's birthplace.\n",
            "\n",
            "Action: Retrieval\n",
            "Action Input: \"Wilhelm Müller birthplace\"\n",
            "[DEBUG] Action: retrieval\n",
            "[DEBUG] Action Input: Wilhelm Müller birthplace\n",
            "[DEBUG] Observation: [Document 1] : Early life and education.Max Müller was born into a cultured family on 6 December 1823 in <a href=\"Dessau\">Dessau</a>, the son of <a href=\"Wilhelm%20M%C3%BCller\">Wilhelm Müller</a>, a <a href=\"Lyric%20poetry\">lyric poet</a> whose verse <a href=\"Franz%20Schubert\">Franz Schubert</a> had set to music in his song-cycles <i><a href=\"Die%20sch%C3%B6ne%20M%C3%BCllerin\">Die schöne Müllerin</a></i> and <i><a href=\"Winterreise\">Winterreise</a></i>. His mother, Adelheid Müller (née von Basedow), was the eldest daughter of a prime minister of <a href=\"Anhalt-Dessau\">Anhalt-Dessau</a>. <a href=\"Carl%20Maria%20von%20Weber\">Carl Maria von Weber</a> was a <a href=\"godparent\">godfather</a>.\n",
            "[Document 2] : Wilhelm Müller was born on 7 October 1794 at Dessau, the son of a tailor. He was educated at the gymnasium of his native town and at the University of Berlin, where he devoted himself to philological and historical studies. In 1813-1814 he took part, as a volunteer in the Prussian army, in the national rising against Napoleon. He participated in the battles of Lützen, Bautzen, Hanau and Kulm. In 1814 he returned to his studies at Berlin. From 1817 to 1819, he visited southern Germany and Italy, and in 1820 published his impressions of the latter in Rom, Römer und Römerinnen. In 1819, he was appointed teacher of classics in the Gelehrtenschule at Dessau, and in 1820 librarian to the ducal library. He remained there the rest of his life, dying of a heart attack aged only 32. Müller's son, Friedrich Max Müller, was an English orientalist who founded the comparative study of religions; his grandson Wilhelm Max Müller was an American Oriental scholar.\n",
            "[Document 3] : Wilhelm Max Müller (15 May 1862 – July 1919) was an <a href=\"Americans\">American</a> <a href=\"Oriental%20studies\">orientalist</a>.\n",
            "\n",
            "Biography.He was born at <a href=\"Glei%C3%9Fenberg\">Gleißenberg</a>, <a href=\"German%20Confederation\">Germany</a>, the son of <a href=\"Friedrich%20Max%20M%C3%BCller\">Friedrich Max Müller</a> and the grandson of German romantic poet <a href=\"Wilhelm%20M%C3%BCller\">Wilhelm Müller</a>. He was educated at <a href=\"University%20of%20Erlangen\">Erlangen</a>, <a href=\"Humboldt%20University%20of%20Berlin\">Berlin</a>, <a href=\"University%20of%20Munich\">Munich</a>, and <a href=\"University%20of%20Leipzig\">Leipzig</a>, where he received his <a href=\"Ph.D.\">Ph.D.</a> He was one of the last students of the Egyptologist <a href=\"Georg%20Ebers\">Georg Ebers</a>.\n",
            "\n",
            "\n",
            ">> Thought: I have found the information about Wilhelm Müller's birthplace.\n",
            "\n",
            "Action: Response To Question\n",
            "Response: Germany\n",
            "[DEBUG] Action: response to question\n",
            "[DEBUG] Action Input: None\n",
            "[DEBUG] Response: Germany\n",
            "\n",
            "\n",
            "===> Final response <===\n",
            "Pergunta: Who owned the Rochester Rhinos when Glenn left the team?\n",
            "Resposta verdadeira: Rochester, New York,\n",
            "Resposta gerada pelo modelo: Rob Clark\n",
            "\n",
            "\n",
            "Pergunta: In which country was Wilhelm Müller born?\n",
            "Resposta verdadeira: Germany \n",
            "Resposta gerada pelo modelo: Germany\n",
            "\n",
            "\n",
            "Question: [1/50]\n",
            "Question: [2/50]\n",
            "Question: [3/50]\n",
            "Question: [4/50]\n",
            "Question: [5/50]\n",
            "Question: [6/50]\n",
            "Question: [7/50]\n",
            "Question: [8/50]\n",
            "Question: [9/50]\n",
            "Question: [10/50]\n",
            "Question: [11/50]\n",
            "Question: [12/50]\n",
            "Question: [13/50]\n",
            "Question: [14/50]\n",
            "Question: [15/50]\n",
            "Question: [16/50]\n",
            "Question: [17/50]\n",
            "Question: [18/50]\n",
            "Question: [19/50]\n",
            "Question: [20/50]\n",
            "Question: [21/50]\n",
            "Question: [22/50]\n",
            "Question: [23/50]\n",
            "Question: [24/50]\n",
            "Question: [25/50]\n",
            "Question: [26/50]\n",
            "Question: [27/50]\n",
            "Question: [28/50]\n",
            "Question: [29/50]\n",
            "Question: [30/50]\n",
            "Question: [31/50]\n",
            "Question: [32/50]\n",
            "Question: [33/50]\n",
            "Question: [34/50]\n",
            "Question: [35/50]\n",
            "Question: [36/50]\n",
            "Question: [37/50]\n",
            "Question: [38/50]\n",
            "Question: [39/50]\n",
            "Question: [40/50]\n",
            "Question: [41/50]\n",
            "Question: [42/50]\n",
            "Question: [43/50]\n",
            "Question: [44/50]\n",
            "Question: [45/50]\n",
            "Question: [46/50]\n",
            "Question: [47/50]\n",
            "Question: [48/50]\n",
            "Question: [49/50]\n",
            "Question: [50/50]\n",
            "Total de perguntas: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Função para tokenizar o texto (converter em minúsculas e dividir em palavras)\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Função para calcular o F1-Score usando a técnica de Bag of Words (BoW)\n",
        "def bag_of_words_f1(reference, generated):\n",
        "    # Verifica se a resposta verdadeira ou a resposta gerada são None\n",
        "    if reference is None or generated is None:\n",
        "        return 0\n",
        "\n",
        "    # Tokeniza a referência e a resposta gerada\n",
        "    ref_tokens = tokenize(reference)\n",
        "    gen_tokens = tokenize(generated)\n",
        "\n",
        "    # Converte os tokens para Counter (bag of words)\n",
        "    ref_bag = Counter(ref_tokens)\n",
        "    gen_bag = Counter(gen_tokens)\n",
        "\n",
        "    # Calcula a interseção e a união dos conjuntos de tokens\n",
        "    common_tokens = ref_bag & gen_bag\n",
        "    correct = sum(common_tokens.values())\n",
        "\n",
        "    # Verifica se uma das respostas está vazia\n",
        "    if len(ref_bag) == 0 or len(gen_bag) == 0:\n",
        "        # Se ambos estiverem vazios, o F1 é 1 se forem iguais, 0 caso contrário\n",
        "        return int(ref_tokens == gen_tokens)\n",
        "\n",
        "    # Se não houver tokens em comum, o F1 é 0\n",
        "    if correct == 0:\n",
        "        return 0\n",
        "\n",
        "    # Calcula a precisão e o recall\n",
        "    precision = 1.0 * correct / len(gen_tokens)\n",
        "    recall = 1.0 * correct / len(ref_tokens)\n",
        "\n",
        "    # Cálculo do F1-Score\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "    return f1\n",
        "\n",
        "# Função para calcular a correspondência exata (Exact Match)\n",
        "def exact_match(reference, generated):\n",
        "    # Verifica se a resposta verdadeira ou a resposta gerada são None\n",
        "    if reference is None or generated is None:\n",
        "        return 0\n",
        "    ref = reference.strip().lower()  # Remove espaços extras e converte para minúsculas\n",
        "    gen = generated.strip().lower()\n",
        "\n",
        "    return int(ref == gen)  # Retorna 1 se forem iguais, 0 caso contrário\n",
        "\n",
        "# Exemplo de uso das funções\n",
        "reference = \"Ground truth\"  # Resposta verdadeira\n",
        "generated = \"Example response: ground truth\"  # Resposta gerada pelo modelo\n",
        "\n",
        "# Calcula o F1-Score usando Bag of Words\n",
        "f1 = bag_of_words_f1(reference, generated)\n",
        "print(\"Exemplo de F1-BoW\")\n",
        "print(f\"Resposta verdadeira: {reference}\")\n",
        "print(f\"Saída do modelo: {generated}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")  # Exibe o F1-Score com 4 casas decimais\n",
        "print(f\"Correspondência exata: {exact_match(reference, generated)}\")  # Exibe o resultado de correspondência exata\n"
      ],
      "metadata": {
        "id": "qTs6HfvZOUae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e37c78-0140-4bc8-bbde-7c39126e4ead"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplo de F1-BoW\n",
            "Resposta verdadeira: Ground truth\n",
            "Saída do modelo: Example response: ground truth\n",
            "F1-Score: 0.6667\n",
            "Correspondência exata: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Avaliação de performance do modelo\n",
        "\n",
        "n = len(results[\"Question\"])  # Número total de perguntas processadas\n",
        "f1_score = []  # Lista para armazenar os valores do F1-Score para cada pergunta\n",
        "exact_match_value = []  # Lista para armazenar os valores de correspondência exata (exact match) para cada pergunta\n",
        "\n",
        "# Itera sobre cada pergunta e calcula o F1-Score e o valor de correspondência exata\n",
        "for i in range(n):\n",
        "    # Calcula o F1-Score usando Bag of Words e armazena o resultado\n",
        "    f1_score.append(bag_of_words_f1(results[\"Ground truth\"][i], results[\"Model response\"][i]))\n",
        "    # Calcula a correspondência exata e armazena o resultado\n",
        "    exact_match_value.append(exact_match(results[\"Ground truth\"][i], results[\"Model response\"][i]))\n",
        "\n",
        "# Calcula a taxa de correspondência exata (em porcentagem)\n",
        "exact_rate = np.mean(exact_match_value) * 100\n",
        "\n",
        "# Exibe os resultados de performance\n",
        "print(f\"Total de perguntas: {n}\")  # Exibe o número total de perguntas\n",
        "print(f\"Média F1-Score : {np.mean(f1_score):.4f}\")  # Exibe a média do F1-Score com 4 casas decimais\n",
        "print(f\"Taxa de correspondência: [{sum(exact_match_value)}/{n}], {exact_rate:.2f}%\")  # Exibe a taxa de correspondência exata\n"
      ],
      "metadata": {
        "id": "OgkZHuIoO7qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3105f1-be80-45d1-bb32-be5bb9cf5062"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de perguntas: 40\n",
            "Média F1-Score : 0.2882\n",
            "Taxa de correspondência: [8/40], 20.00%\n"
          ]
        }
      ]
    }
  ]
}