{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rren_yUWKJfj"
      },
      "source": [
        "# Prompt Engineering com IMDB\n",
        "\n",
        "Juvenal Jr. - 242160\n",
        "\n",
        "> Utilizar o groq.com para usar a API do Llama 3.1-8b para fazer análise de sentimentos do IMDB."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install groq\n",
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF_9IMc-KkIZ",
        "outputId": "c05d0dab-0a55-4ef6-b473-91455473cd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n",
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.35.27-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.9.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.27 (from boto3)\n",
            "  Downloading botocore-1.35.27-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.27->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.27->boto3) (1.16.0)\n",
            "Downloading boto3-1.35.27-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.27-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses, jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.27 botocore-1.35.27 jmespath-1.0.1 s3transfer-0.10.2 sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8oFAsRoKJfl"
      },
      "outputs": [],
      "source": [
        "import os # Operações com o SO (ler variáveis de ambiente)\n",
        "import random # Operações randômicas\n",
        "from concurrent.futures import ThreadPoolExecutor # Paralelização\n",
        "import threading # Paralelização\n",
        "import time # Temporização\n",
        "from typing import Optional, List # Type hints\n",
        "import datasets # Obter o dataset IMDB\n",
        "import groq # API para utilizar o Llama 3\n",
        "import tqdm # Print de progresso\n",
        "import torch # ML\n",
        "import pandas # Data manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oui9N1GSKJfm"
      },
      "source": [
        "## Interface para o Groq\n",
        "\n",
        "Para realizar a inferência utilizando a API do Groq, criamos uma classe:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GroqInterface:\n",
        "    '''\n",
        "    Interface para utilizar a API Groq.\n",
        "    '''\n",
        "\n",
        "    _client = None  # Armazena uma instância única do cliente da API Groq (padrão Singleton).\n",
        "\n",
        "    LLAMA3_31_8B_INSTANT = \"llama-3.1-8b-instant\"  # Define o modelo correto a ser utilizado.\n",
        "\n",
        "    rate_lock = threading.Lock()  # Cria um bloqueio para controlar o limite de taxa em cenários multithreading.\n",
        "\n",
        "    def __init__(self, model: Optional[str] = None):\n",
        "        '''\n",
        "        Construtor da classe GroqInterface.\n",
        "        '''\n",
        "        if GroqInterface._client is None:\n",
        "            api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "            if api_key is None:\n",
        "                raise RuntimeError(\"A chave de API não está nas variáveis de ambiente ('GROQ_API_KEY' não foi definida).\")\n",
        "            GroqInterface._client = groq.Groq(api_key=api_key)\n",
        "\n",
        "        if model is None:\n",
        "            model = GroqInterface.LLAMA3_31_8B_INSTANT  # Use o modelo `llama-3.1-8b-instant`.\n",
        "        self._model = model\n",
        "\n",
        "    def __call__(self, prompt: str) -> str:\n",
        "        '''\n",
        "        Gera uma resposta do modelo.\n",
        "        '''\n",
        "        done = False\n",
        "        while not done:\n",
        "            try:\n",
        "                with GroqInterface.rate_lock:\n",
        "                    chat_completion = GroqInterface._client.chat.completions.create(\n",
        "                        messages=[\n",
        "                            {\"role\": \"user\", \"content\": prompt}\n",
        "                        ],\n",
        "                        model=self._model,\n",
        "                    )\n",
        "                done = True\n",
        "            except groq.RateLimitError:\n",
        "                time.sleep(2)\n",
        "            except groq.NotFoundError as exception:\n",
        "                raise exception\n",
        "            except Exception as exception:\n",
        "                raise exception\n",
        "\n",
        "        return chat_completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "Ydya1iw2tjXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a variável de ambiente com sua chave de API\n",
        "os.environ['GROQ_API_KEY'] = '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'\n",
        "\n",
        "# Agora você pode inicializar o GroqInterface sem erros\n",
        "groq_interface = GroqInterface()\n"
      ],
      "metadata": {
        "id": "B9LXkmOAMUMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = GroqInterface._client.models.list()\n",
        "for model in models.data:\n",
        "    print(model.id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usudox1c-Quj",
        "outputId": "1074c115-04f0-4c69-d7e7-e12a737fc36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distil-whisper-large-v3-en\n",
            "llama-3.1-8b-instant\n",
            "llama3-8b-8192\n",
            "llama-3.2-1b-preview\n",
            "llama3-groq-70b-8192-tool-use-preview\n",
            "mixtral-8x7b-32768\n",
            "llama-3.2-11b-text-preview\n",
            "llama3-groq-8b-8192-tool-use-preview\n",
            "gemma-7b-it\n",
            "llava-v1.5-7b-4096-preview\n",
            "llama-3.2-3b-preview\n",
            "whisper-large-v3\n",
            "llama-3.2-90b-text-preview\n",
            "llama3-70b-8192\n",
            "llama-3.1-70b-versatile\n",
            "llama-guard-3-8b\n",
            "gemma2-9b-it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pA2pVfz4KJfn",
        "outputId": "13714a6d-25d2-41ca-d5ec-3e76b2f729e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "groq_interface(\"Hello!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsZBaxOdKJfn"
      },
      "outputs": [],
      "source": [
        "POSITIVE = 1\n",
        "NEGATIVE = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GroqSentimentInterface(GroqInterface):\n",
        "    '''\n",
        "    Classe que estende a GroqInterface, adicionando um pós-processamento\n",
        "    para análise de sentimentos.\n",
        "    '''\n",
        "\n",
        "    def __call__(self, prompt: str) -> int:\n",
        "        '''\n",
        "        Gera a resposta do modelo para análise de sentimentos.\n",
        "\n",
        "        Se o modelo fornecer uma resposta ambígua (contendo tanto termos positivos\n",
        "        quanto negativos), um valor aleatório é gerado.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): o prompt enviado para o modelo.\n",
        "\n",
        "        Retorna:\n",
        "            int: resposta do modelo. Retorna POSITIVE se o sentimento for positivo,\n",
        "                 ou NEGATIVE em caso contrário.\n",
        "        '''\n",
        "\n",
        "        # Chama o método __call__ da classe base (GroqInterface) para obter a resposta do modelo.\n",
        "        response = super().__call__(prompt)\n",
        "\n",
        "        # Converte a resposta para letras minúsculas para facilitar a comparação.\n",
        "        response = response.lower()\n",
        "\n",
        "        # Verifica se a resposta contém a palavra \"positive\" e não contém \"negative\".\n",
        "        if \"positive\" in response and \"negative\" not in response:\n",
        "            return POSITIVE  # Retorna POSITIVE se a condição for verdadeira.\n",
        "\n",
        "        # Verifica se a resposta contém a palavra \"negative\" e não contém \"positive\".\n",
        "        if \"negative\" in response and \"positive\" not in response:\n",
        "            return NEGATIVE  # Retorna NEGATIVE se a condição for verdadeira.\n",
        "\n",
        "        # Se a resposta for ambígua (contém tanto positivo quanto negativo),\n",
        "        # escolhe aleatoriamente entre POSITIVE e NEGATIVE.\n",
        "        return random.choice([POSITIVE, NEGATIVE])\n"
      ],
      "metadata": {
        "id": "fIfdNpxGt1Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9kCqIE7KJfn"
      },
      "outputs": [],
      "source": [
        "groq_sentiment = GroqSentimentInterface()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JrQeWyXKJfo"
      },
      "source": [
        "## IMDB Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "executor = ThreadPoolExecutor(max_workers=2)\n",
        "# Cria um executor com pool de threads, permitindo execução paralela de até 2 tarefas.\n",
        "\n",
        "trainbase_future = executor.submit(datasets.load_dataset, \"imdb\", split=\"train\")\n",
        "# Envia uma tarefa para o executor carregar o dataset de treino do IMDB de forma assíncrona,\n",
        "# ou seja, em uma thread separada. O resultado dessa tarefa será obtido posteriormente.\n",
        "\n",
        "test_future = executor.submit(datasets.load_dataset, \"imdb\", split='test')\n",
        "# Envia outra tarefa para o executor carregar o dataset de teste do IMDB de forma assíncrona.\n",
        "\n",
        "trainbase_dataset = trainbase_future.result()\n",
        "# Obtém o resultado da tarefa assíncrona de carregar o dataset de treino (espera até que a tarefa seja concluída).\n",
        "\n",
        "testbase_dataset = test_future.result()\n",
        "# Obtém o resultado da tarefa assíncrona de carregar o dataset de teste (espera até que a tarefa seja concluída).\n",
        "\n",
        "train_val_dataset = trainbase_dataset.train_test_split(test_size=100, shuffle=True, seed=78)\n",
        "# Divide o dataset de treino em duas partes: treino e validação. Seleciona 300 amostras aleatórias para validação,\n",
        "# embaralhando os dados antes de fazer a divisão. A seed garante a reprodução do embaralhamento.\n",
        "\n",
        "discard_test_dataset = testbase_dataset.train_test_split(test_size=100, shuffle=True, seed=78)\n",
        "# Divide o dataset de teste, descartando parte dos dados para obter um conjunto menor de teste\n",
        "# com 300 amostras. O embaralhamento também é controlado por uma seed.\n",
        "\n",
        "train_dataset = train_val_dataset[\"train\"]\n",
        "# Extrai o conjunto de treino da divisão feita anteriormente.\n",
        "\n",
        "val_dataset = train_val_dataset[\"test\"]\n",
        "# Extrai o conjunto de validação da divisão feita anteriormente.\n",
        "\n",
        "test_dataset = discard_test_dataset[\"test\"]\n",
        "# Extrai o novo conjunto de teste, a partir da divisão anterior.\n"
      ],
      "metadata": {
        "id": "jCthx6DiZlZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gokayCMKKJfo",
        "outputId": "1eabbee9-9b53-4278-802a-95b78105e683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24900, 100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8r1DRPwKJfo"
      },
      "source": [
        "## Zero-shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUiJHZbHKJfo"
      },
      "source": [
        "Para a técnica de zero-shot, precisamos apenas preparar um prompt que solicita a classificação ao modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM7SiihJKJfo"
      },
      "outputs": [],
      "source": [
        "base_prompt_zero = '''Classify if the movie review is POSITIVE or NEGATIVE:\n",
        "                Review:\n",
        "                {review}\n",
        "\n",
        "                Sentiment:\n",
        "                POSITIVE OR NEGATIVE:\n",
        "                '''\n",
        "# Este é um template de prompt utilizado para solicitar ao modelo que classifique uma resenha de filme.\n",
        "# A variável {review} será substituída pelo texto da resenha do filme.\n",
        "# O modelo deve indicar se o sentimento da resenha é POSITIVO ou NEGATIVO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HInGTLUKJfo",
        "outputId": "bcc8228f-feac-4597-a4f9-b9ef4c6c01be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "prompt = base_prompt_zero.format(review=train_dataset[-1][\"text\"])\n",
        "# Substitui o placeholder {review} no template base_prompt_zero pelo texto da última resenha\n",
        "# presente no dataset de treino (train_dataset[-1][\"text\"]).\n",
        "\n",
        "groq_sentiment(prompt), train_dataset[-1][\"label\"]\n",
        "# Envia o prompt gerado para o modelo groq_sentiment, que faz a análise de sentimento\n",
        "# (retorna POSITIVE ou NEGATIVE).\n",
        "# Ao mesmo tempo, exibe o rótulo real (label) da última resenha no dataset de treino,\n",
        "# para comparar o resultado gerado pelo modelo com o rótulo original.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x65KAOYKJfo"
      },
      "source": [
        "Preparamos a função para realizar a avaliação de um sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZkwKJc9KJfo"
      },
      "outputs": [],
      "source": [
        "def evaluate_zero(text:str, label:int) -> bool:\n",
        "    '''\n",
        "    Avalia a resposta do modelo em um cenário de zero-shot (sem treino específico para o conjunto de dados).\n",
        "\n",
        "    Args:\n",
        "        text (str): resenha (texto) a ser avaliada.\n",
        "        label (int): rótulo esperado da resenha (sentimento correto, 0 para negativo e 1 para positivo).\n",
        "\n",
        "    Retorna:\n",
        "        bool: True se o modelo classificar corretamente, False caso contrário.\n",
        "    '''\n",
        "    # Formata o prompt usando o template base, inserindo a resenha no lugar do {review}.\n",
        "    prompt = base_prompt_zero.format(review=text)\n",
        "\n",
        "    # Obtém o resultado da análise de sentimento usando o modelo groq_sentiment.\n",
        "    result = groq_sentiment(prompt)\n",
        "\n",
        "    # Compara o resultado gerado pelo modelo com o rótulo esperado e retorna True se estiver correto.\n",
        "    return result == label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcS6BcN_KJfp"
      },
      "source": [
        "E calculamos a acurácia utilizando os dados de validação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dwd-kU6KJfp",
        "outputId": "a6562f40-0adb-4bb4-efc5-f5fa4d9fa8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [05:30<00:00,  3.31s/it]\n"
          ]
        }
      ],
      "source": [
        "executor = ThreadPoolExecutor(max_workers=4) # Mais trabalhadores -> Mais exceções de RateLimit\n",
        "# Cria um executor com um pool de threads que pode executar até 4 tarefas em paralelo.\n",
        "# Se o número de trabalhadores (threads) for muito alto, pode aumentar a ocorrência de exceções de RateLimit,\n",
        "# devido ao número elevado de requisições simultâneas à API.\n",
        "\n",
        "futures = []\n",
        "# Lista para armazenar as tarefas futuras (operações assíncronas).\n",
        "\n",
        "for data in val_dataset:\n",
        "    future = executor.submit(evaluate_zero, **data)\n",
        "    # Envia a função evaluate_zero para ser executada em paralelo usando o executor.\n",
        "    # Cada item do val_dataset contém os dados que são passados como argumentos (text e label) para a função evaluate_zero.\n",
        "    futures.append(future)\n",
        "    # Adiciona cada tarefa assíncrona (futura) à lista de futures.\n",
        "\n",
        "correct_zero = 0\n",
        "# Inicializa o contador de classificações corretas.\n",
        "\n",
        "for future in tqdm.tqdm(futures):\n",
        "    correct_zero += future.result()\n",
        "    # Para cada tarefa futura, obtém o resultado da função evaluate_zero (True ou False).\n",
        "    # Se o resultado for True (classificação correta), incrementa o contador correct_zero.\n",
        "    # A barra de progresso tqdm é utilizada para mostrar o progresso da execução das tarefas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmHI28VLKJfp",
        "outputId": "04d8f93f-2864-410c-98bf-1b9aab67a8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia - Zero-shot - Validação: 90.0%\n"
          ]
        }
      ],
      "source": [
        "accuracy_zero = correct_zero/len(val_dataset)\n",
        "print(f\"Acurácia - Zero-shot - Validação: {accuracy_zero*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASdViRvuKJfp"
      },
      "source": [
        "## Few-shot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_prompt_few = '''Classify if the movie review is positive or negative:\n",
        "                # Inicia o prompt, pedindo ao modelo para classificar se a resenha do filme é positiva ou negativa.\n",
        "\n",
        "                Review:\n",
        "                Movie review\n",
        "                # Aqui o prompt estabelece o campo \"Review\" e coloca um texto genérico \"Movie review\", que será substituído mais tarde por exemplos reais de resenhas.\n",
        "\n",
        "                Sentiment:\n",
        "                ONLY POSITIVE OR NEGATIVE\n",
        "                # Especifica que a resposta do modelo deve ser limitada a \"POSITIVE\" ou \"NEGATIVE\", restringindo as possibilidades de resposta.\n",
        "\n",
        "                Classify if this movie review is positive or negative:\n",
        "                Review:\n",
        "                {example1}\n",
        "                # Aqui é fornecido o primeiro exemplo de resenha de filme que será injetado via o placeholder \"{example1}\".\n",
        "\n",
        "                Sentiment:\n",
        "                {response1}\n",
        "                # O sentimento correspondente ao primeiro exemplo é inserido no placeholder \"{response1}\", indicando se é \"POSITIVE\" ou \"NEGATIVE\".\n",
        "\n",
        "                Classify if this movie review is positive or negative:\n",
        "                Review:\n",
        "                {example2}\n",
        "                # Fornece o segundo exemplo de resenha de filme, também usando um placeholder \"{example2}\".\n",
        "\n",
        "                Sentiment:\n",
        "                {response2}\n",
        "                # O sentimento do segundo exemplo é inserido aqui através de \"{response2}\", que será preenchido com \"POSITIVE\" ou \"NEGATIVE\".\n",
        "\n",
        "                Classify if this movie review is positive or negative:\n",
        "                Review:\n",
        "                {{review}}\n",
        "                # Esta parte final do prompt solicita a classificação da nova resenha, que será substituída pelo texto real através do placeholder \"{{review}}\".\n",
        "\n",
        "                Sentiment:\n",
        "                # Aqui, o modelo deve prever se o sentimento da resenha é \"POSITIVE\" ou \"NEGATIVE\".\n",
        "                '''\n"
      ],
      "metadata": {
        "id": "uff1sN7Tj8Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_example = None\n",
        "negative_example = None\n",
        "# Inicializa as variáveis 'positive_example' e 'negative_example' como None.\n",
        "# Elas serão usadas para armazenar exemplos de resenhas classificadas como positivas e negativas, respectivamente.\n",
        "\n",
        "i = 0\n",
        "# Inicializa o contador 'i' com valor 0. Este será usado para percorrer os dados do conjunto de treino.\n",
        "\n",
        "while positive_example is None or negative_example is None:\n",
        "    # O loop 'while' continua até que ambas as variáveis 'positive_example' e 'negative_example'\n",
        "    # sejam preenchidas com exemplos, ou seja, enquanto pelo menos uma delas for 'None'.\n",
        "\n",
        "    if train_dataset[i][\"label\"] == POSITIVE:\n",
        "        positive_example = train_dataset[i]\n",
        "        # Se o rótulo do exemplo atual do dataset for positivo (representado pela constante 'POSITIVE'),\n",
        "        # armazena esse exemplo em 'positive_example'.\n",
        "    else:\n",
        "        negative_example = train_dataset[i]\n",
        "        # Caso contrário, se o rótulo for negativo, armazena o exemplo em 'negative_example'.\n",
        "\n",
        "    i += 1\n",
        "    # Incrementa o valor de 'i' para avançar para o próximo exemplo no conjunto de treino na próxima iteração.\n"
      ],
      "metadata": {
        "id": "btkZs6IokLTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_prompt_few = raw_prompt_few.format(example1=positive_example[\"text\"], response1=\"POSITIVE\",\n",
        "                                        example2=negative_example[\"text\"], response2=\"NEGATIVE\")\n",
        "# O método 'format' é usado para preencher os placeholders na string 'raw_prompt_few'.\n",
        "# - 'example1=positive_example[\"text\"]' insere o texto do exemplo positivo armazenado em 'positive_example[\"text\"]' no placeholder '{example1}'.\n",
        "# - 'response1=\"POSITIVE\"' insere a string \"POSITIVE\" no placeholder '{response1}', que indica o sentimento associado ao primeiro exemplo.\n",
        "# - 'example2=negative_example[\"text\"]' insere o texto do exemplo negativo armazenado em 'negative_example[\"text\"]' no placeholder '{example2}'.\n",
        "# - 'response2=\"NEGATIVE\"' insere a string \"NEGATIVE\" no placeholder '{response2}', que indica o sentimento associado ao segundo exemplo.\n",
        "# O resultado é que a string 'raw_prompt_few' se torna um prompt preenchido com exemplos reais de resenhas positivas e negativas.\n",
        "\n",
        "print(base_prompt_few)\n",
        "# Imprime o 'base_prompt_few', que agora contém o prompt formatado com as resenhas e suas classificações.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud05Aspdkc8t",
        "outputId": "01e459fd-4472-4ae9-ff4b-6a63820ff797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classify if the movie review is positive or negative:\n",
            "                # Inicia o prompt, pedindo ao modelo para classificar se a resenha do filme é positiva ou negativa.\n",
            "\n",
            "                Review:\n",
            "                Movie review\n",
            "                # Aqui o prompt estabelece o campo \"Review\" e coloca um texto genérico \"Movie review\", que será substituído mais tarde por exemplos reais de resenhas.\n",
            "\n",
            "                Sentiment:\n",
            "                ONLY POSITIVE OR NEGATIVE\n",
            "                # Especifica que a resposta do modelo deve ser limitada a \"POSITIVE\" ou \"NEGATIVE\", restringindo as possibilidades de resposta.\n",
            "\n",
            "                Classify if this movie review is positive or negative:\n",
            "                Review:\n",
            "                but I want to say I cannot agree more with Moira.<br /><br />What a wonderful film.<br /><br />I was thinking about it just this morning, wanting to give advice to some dopey sod who'd lost money on his debit card through fraud, and wanted to say 'Keep thy money in thine pocket' and realised I was talking like James Mason.<br /><br />Even tho he didn't say those words, I still think he would! I've never forgotten 'Are ye carrying?' in his reconciliation with his son, Hywel Bennet: 'Always have money in thine pocket!' Good advice.<br /><br />Not enough kids have fathers with such unforgiving but well-meant attitudes any more. Or any father at all.<br /><br />It would be a good thing for us to reinstate 'thee', 'thy' and 'thine' in our language to show we care. It is only the same as 'tutoyer' in French or 'du' in German.<br /><br />Addendum: I just realised that a lot of my remarks were about James Mason in The Family Way!<br /><br />I think it's because I mixed up Susan George with Hayley Mills. Well, easy mistake.<br /><br />I stand by the comments tho'.<br /><br />And Spring and Port Wine is so very similar to The Family Way.<br /><br />When you took a girlfriend to the pictures in those days, you really had something to say and talk about afterwards, something that affected your knowledge of the world and your personal development.<br /><br />Theatrical experiences are almost real, and they are important in helping young people to grow up.<br /><br />It doesn't happen now, I think, that teenagers can just go to the pics like we did.\n",
            "                # Aqui é fornecido o primeiro exemplo de resenha de filme que será injetado via o placeholder \"but I want to say I cannot agree more with Moira.<br /><br />What a wonderful film.<br /><br />I was thinking about it just this morning, wanting to give advice to some dopey sod who'd lost money on his debit card through fraud, and wanted to say 'Keep thy money in thine pocket' and realised I was talking like James Mason.<br /><br />Even tho he didn't say those words, I still think he would! I've never forgotten 'Are ye carrying?' in his reconciliation with his son, Hywel Bennet: 'Always have money in thine pocket!' Good advice.<br /><br />Not enough kids have fathers with such unforgiving but well-meant attitudes any more. Or any father at all.<br /><br />It would be a good thing for us to reinstate 'thee', 'thy' and 'thine' in our language to show we care. It is only the same as 'tutoyer' in French or 'du' in German.<br /><br />Addendum: I just realised that a lot of my remarks were about James Mason in The Family Way!<br /><br />I think it's because I mixed up Susan George with Hayley Mills. Well, easy mistake.<br /><br />I stand by the comments tho'.<br /><br />And Spring and Port Wine is so very similar to The Family Way.<br /><br />When you took a girlfriend to the pictures in those days, you really had something to say and talk about afterwards, something that affected your knowledge of the world and your personal development.<br /><br />Theatrical experiences are almost real, and they are important in helping young people to grow up.<br /><br />It doesn't happen now, I think, that teenagers can just go to the pics like we did.\".\n",
            "\n",
            "                Sentiment:\n",
            "                POSITIVE\n",
            "                # O sentimento correspondente ao primeiro exemplo é inserido no placeholder \"POSITIVE\", indicando se é \"POSITIVE\" ou \"NEGATIVE\".\n",
            "\n",
            "                Classify if this movie review is positive or negative:\n",
            "                Review:\n",
            "                \"A total waste of time\" Just throw in a few explosions, non stop fighting, exotic cars a deranged millionaire, slow motion computer generated car crashes and last but not least a Hugh Hefner like character with wall to wall hot babes, and mix in a blender and you will have this sorry excuse for a movie. I really got a laugh out of the \"Dr. Evil\" like heavily fortified compound. The plot was somewhere between preposterous and non existent. How many millionaires are willing to make a 25 million dollar bet on a car race? Answer: 4 but, didn't they become millionaires through fiscal responsibility? This was written for pubescent males, it plays like a video game. I did enjoy the Gulfstream II landing in the desert though.\n",
            "                # Fornece o segundo exemplo de resenha de filme, também usando um placeholder \"\"A total waste of time\" Just throw in a few explosions, non stop fighting, exotic cars a deranged millionaire, slow motion computer generated car crashes and last but not least a Hugh Hefner like character with wall to wall hot babes, and mix in a blender and you will have this sorry excuse for a movie. I really got a laugh out of the \"Dr. Evil\" like heavily fortified compound. The plot was somewhere between preposterous and non existent. How many millionaires are willing to make a 25 million dollar bet on a car race? Answer: 4 but, didn't they become millionaires through fiscal responsibility? This was written for pubescent males, it plays like a video game. I did enjoy the Gulfstream II landing in the desert though.\".\n",
            "\n",
            "                Sentiment:\n",
            "                NEGATIVE\n",
            "                # O sentimento do segundo exemplo é inserido aqui através de \"NEGATIVE\", que será preenchido com \"POSITIVE\" ou \"NEGATIVE\".\n",
            "\n",
            "                Classify if this movie review is positive or negative:\n",
            "                Review:\n",
            "                {review}\n",
            "                # Esta parte final do prompt solicita a classificação da nova resenha, que será substituída pelo texto real através do placeholder \"{review}\".\n",
            "\n",
            "                Sentiment:\n",
            "                # Aqui, o modelo deve prever se o sentimento da resenha é \"POSITIVE\" ou \"NEGATIVE\".\n",
            "                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = base_prompt_few.format(review=train_dataset[-1][\"text\"])\n",
        "# Usa o método 'format()' novamente para preencher o placeholder '{{review}}' dentro da string 'base_prompt_few' com o texto da última resenha do 'train_dataset'.\n",
        "# 'train_dataset[-1][\"text\"]' seleciona a última resenha no conjunto de treinamento (o índice [-1] refere-se ao último item da lista).\n",
        "# O resultado é que o 'prompt' agora contém a string formatada com dois exemplos anteriores (um positivo e um negativo) e a nova resenha do dataset.\n",
        "\n",
        "groq_sentiment(prompt), train_dataset[-1][\"label\"]\n",
        "# Chama a função 'groq_sentiment()', passando o 'prompt' como argumento. Provavelmente, essa função realiza a classificação de sentimento (ou análise de sentimento) com base no prompt fornecido.\n",
        "# Em seguida, 'train_dataset[-1][\"label\"]' retorna o rótulo real (ou seja, o sentimento real) da última resenha no conjunto de treinamento.\n",
        "# O resultado dessa linha retorna uma tupla contendo:\n",
        "# 1. O sentimento previsto pela função 'groq_sentiment(prompt)'.\n",
        "# 2. O rótulo real da resenha (positivo ou negativo) a partir do 'train_dataset[-1][\"label\"]'.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R2EoLkBkv95",
        "outputId": "8bed9d76-67e9-4556-f80a-715f5c491e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_few(text: str, label: int) -> bool:\n",
        "    '''\n",
        "    Avalia a resposta do modelo usando few-shot learning.\n",
        "\n",
        "    Args:\n",
        "        text (str): A resenha que será avaliada.\n",
        "        label (int): O rótulo esperado para a resenha (pode ser uma constante, como 0 para \"NEGATIVE\" e 1 para \"POSITIVE\").\n",
        "\n",
        "    Returns:\n",
        "        bool: Retorna True se o modelo classificar a resenha corretamente, caso contrário, retorna False.\n",
        "    '''\n",
        "\n",
        "    # Preenche o template base (base_prompt_few) com a resenha fornecida (text).\n",
        "    # O placeholder '{{review}}' no 'base_prompt_few' é substituído pelo texto da resenha.\n",
        "    prompt = base_prompt_few.format(review=text)\n",
        "\n",
        "    # Chama a função 'groq_sentiment()', que recebe o 'prompt' formatado como entrada\n",
        "    # e retorna o resultado da classificação de sentimento, seja \"POSITIVE\" ou \"NEGATIVE\".\n",
        "    result = groq_sentiment(prompt)\n",
        "\n",
        "    # Retorna True se a previsão do modelo ('result') for igual ao rótulo esperado ('label').\n",
        "    # Caso contrário, retorna False, indicando que a classificação estava incorreta.\n",
        "    return result == label\n"
      ],
      "metadata": {
        "id": "CCf5wmuHlG2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_few(**train_dataset[-1])\n",
        "# Desempacota o último item do 'train_dataset' como argumentos nomeados para 'evaluate_few'.\n",
        "# Isso equivale a passar 'text=train_dataset[-1][\"text\"]' e 'label=train_dataset[-1][\"label\"]' para a função.\n",
        "# Avalia se o modelo classifica corretamente a última resenha do dataset com base no rótulo esperado.\n"
      ],
      "metadata": {
        "id": "N4f6qlUklscU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d2109d-1928-43c1-9039-48b4af596b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "executor = ThreadPoolExecutor(max_workers=4)\n",
        "# Cria um pool de threads com um máximo de 4 threads (trabalhadores) simultâneas.\n",
        "# Um número maior de trabalhadores pode resultar em mais exceções de RateLimit, indicando que as requisições estão excedendo o limite de taxa permitido.\n",
        "\n",
        "futures = []\n",
        "# Inicializa uma lista vazia para armazenar os objetos 'Future', que representam os resultados das tarefas executadas de forma assíncrona.\n",
        "\n",
        "for data in val_dataset:\n",
        "    future = executor.submit(evaluate_few, **data)\n",
        "    # Para cada item no conjunto de validação (val_dataset), a função 'evaluate_few' é submetida ao 'ThreadPoolExecutor' para ser executada em paralelo.\n",
        "    # Os dados são desempacotados (**data) para serem passados como argumentos nomeados para a função 'evaluate_few'.\n",
        "    # A função 'submit' retorna um objeto 'Future', que será usado para recuperar o resultado da execução da função.\n",
        "    futures.append(future)\n",
        "    # Adiciona cada 'Future' à lista 'futures' para ser processado posteriormente.\n",
        "\n",
        "correct_few = 0\n",
        "# Inicializa um contador para armazenar o número de classificações corretas.\n",
        "\n",
        "for future in tqdm.tqdm(futures):\n",
        "    correct_few += future.result()\n",
        "    # Para cada 'Future' na lista 'futures', usa o método 'result()' para bloquear e esperar o término da execução da função.\n",
        "    # 'future.result()' retorna o valor booleano de 'evaluate_few' (True se a classificação foi correta, False se foi incorreta).\n",
        "    # Se o resultado for True, incrementa 'correct_few', contando as classificações corretas.\n"
      ],
      "metadata": {
        "id": "i2vTNJ8SmFvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a02d65d-a827-4fc7-fbd7-4479a1bd612a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [34:11<00:00, 20.51s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_few = correct_few / len(val_dataset)\n",
        "# Calcula a acurácia da validação few-shot.\n",
        "# 'correct_few' representa o número total de classificações corretas, e 'len(val_dataset)' é o número total de exemplos no conjunto de validação.\n",
        "# A acurácia é obtida dividindo o número de classificações corretas pelo número total de exemplos.\n",
        "\n",
        "print(f\"Acurácia - Few-shot - Validação: {accuracy_few*100}%\")\n",
        "# Exibe a acurácia em formato percentual.\n",
        "# Multiplica 'accuracy_few' por 100 para converter a proporção em uma porcentagem e imprime o valor formatado.\n"
      ],
      "metadata": {
        "id": "HGNUUKSumXJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab1f59a-4f02-4ab2-841a-0481a6c56651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia - Few-shot - Validação: 87.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS890r5tKJfz"
      },
      "source": [
        "## Comparação e Teste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbS7RksxKJfz"
      },
      "source": [
        "Técnica | Acurácia de Validação | Tempo\n",
        "-|-|-\n",
        "Zero-shot|90%|3 min 31 s\n",
        "Few-shot|87%|34 min 11 s\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
